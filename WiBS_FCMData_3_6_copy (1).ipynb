{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "4xHM6noNt1hT",
        "m0m85V7uliwE",
        "6EQ3O1p-aoSM",
        "3UxFUxDxht3r",
        "d7MpABIJh9vk",
        "sHz5jw_skpMH",
        "l7mP1r-rsuNO",
        "02FavhHhu1Pt",
        "Qc-cDjDPMtap",
        "KoX-ZIMkNz-r",
        "2HI2n7fYOk19",
        "qcO21_0WwxlC",
        "bXely-ewzkrz",
        "EciJ2dNT9sn1",
        "WLL0wSH5cJJ_",
        "B3ZsoLRUfcz-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VXBCl4CI867v",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dcf951-23c1-44a4-97e6-220f1f2d5083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "widsdatathon2025.zip\n",
            "Archive:  widsdatathon2025.zip\n",
            "  inflating: Data Dictionary.xlsx    \n",
            "  inflating: SAMPLE_SUBMISSION.xlsx  \n",
            "  inflating: TEST/TEST_CATEGORICAL.xlsx  \n",
            "  inflating: TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv  \n",
            "  inflating: TEST/TEST_QUANTITATIVE_METADATA.xlsx  \n",
            "  inflating: TRAIN/TRAINING_SOLUTIONS.xlsx  \n",
            "  inflating: TRAIN/TRAIN_CATEGORICAL_METADATA.xlsx  \n",
            "  inflating: TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv  \n",
            "  inflating: TRAIN/TRAIN_QUANTITATIVE_METADATA.xlsx  \n"
          ]
        }
      ],
      "source": [
        "#@title uploader\n",
        "file_id = \"1VpSCc_ms2dj59bMAAOqCu0OI0jjb-8Hq\" #@param {type:\"string\"}\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://googledrive.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Replace the assignment below with your file ID\n",
        "# to download a different file.\n",
        "#\n",
        "# A file ID looks like: 1gLBqEWEBQDYbKCDigHnUXNTkzl-OslSO\n",
        "\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, done = downloader.next_chunk()\n",
        "\n",
        "fileId = drive.CreateFile({'id': file_id }) #DRIVE_FILE_ID is file id example: 1iytA1n2z4go3uVCwE_vIKouTKyIDjEq\n",
        "print(fileId['title'])\n",
        "fileId.GetContentFile(fileId['title'])  # Save Drive file as a local file\n",
        "\n",
        "!unzip {fileId['title']}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Prep"
      ],
      "metadata": {
        "id": "dKariRSZ9SHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I don't have this package so I'm installing it. If the cell below doesn't work\n",
        "# for you, you might have to run this before.\n",
        "!pip install geomstats"
      ],
      "metadata": {
        "id": "qeRX0HDd9_tt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa22d38-1bda-4fd4-d522-3ff9e5b77c0e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geomstats\n",
            "  Downloading geomstats-2.8.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: joblib>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.11/dist-packages (from geomstats) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from geomstats) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from geomstats) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.4->geomstats) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->geomstats) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->geomstats) (2025.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.1->geomstats) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->geomstats) (1.17.0)\n",
            "Downloading geomstats-2.8.0-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: geomstats\n",
            "Successfully installed geomstats-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geomstats.datasets.utils as data_utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fcm = pd.read_csv(\"TRAIN/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
        "fcm_solutions = pd.read_excel(\"TRAIN/TRAINING_SOLUTIONS.xlsx\")\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")"
      ],
      "metadata": {
        "id": "DrwNFZnt9M1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5e32ad-4c5f-4d3d-a673-4abc567a3fbf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "i39a5Pk9VWSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fcddcb-ee5a-4f86-9e37-dcea0be985d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch_geometric"
      ],
      "metadata": {
        "id": "o0r467vEWUkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2348272-6cea-4132-b695-b3729cc95294"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "4xHM6noNt1hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fcm.shape"
      ],
      "metadata": {
        "id": "jR_NF3lm_N4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9b4c51-ca33-4e6e-bb07-037251886708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1213, 19901)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcm.describe()"
      ],
      "metadata": {
        "id": "0NPwOG3E_R_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "1a9e4114-44ab-43a1-e5ed-bdaf0f68b193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  0throw_4thcolumn  \\\n",
              "count       1213.000000       1213.000000       1213.000000       1213.000000   \n",
              "mean           0.060553          0.122315          0.060268          0.041287   \n",
              "std            0.064178          0.054026          0.057495          0.043491   \n",
              "min           -0.183279         -0.059932         -0.145566         -0.127827   \n",
              "25%            0.018482          0.086102          0.026548          0.014457   \n",
              "50%            0.058276          0.123220          0.061339          0.043246   \n",
              "75%            0.100103          0.154518          0.099056          0.068408   \n",
              "max            0.321522          0.390895          0.278429          0.189825   \n",
              "\n",
              "       0throw_5thcolumn  0throw_6thcolumn  0throw_7thcolumn  0throw_8thcolumn  \\\n",
              "count       1213.000000       1213.000000       1213.000000       1213.000000   \n",
              "mean           0.069722          0.091007          0.066852          0.000252   \n",
              "std            0.044222          0.049189          0.046864          0.049046   \n",
              "min           -0.072043         -0.079184         -0.105722         -0.164297   \n",
              "25%            0.042462          0.057614          0.036934         -0.031358   \n",
              "50%            0.067066          0.086494          0.067247          0.002549   \n",
              "75%            0.096504          0.119404          0.095117          0.031053   \n",
              "max            0.317500          0.316811          0.270018          0.168196   \n",
              "\n",
              "       0throw_9thcolumn  0throw_10thcolumn  ...  195throw_196thcolumn  \\\n",
              "count       1213.000000        1213.000000  ...           1213.000000   \n",
              "mean           0.014128          -0.002914  ...              0.011075   \n",
              "std            0.038205           0.042462  ...              0.049632   \n",
              "min           -0.137728          -0.148490  ...             -0.161666   \n",
              "25%           -0.010635          -0.030538  ...             -0.021376   \n",
              "50%            0.016130          -0.002604  ...              0.010254   \n",
              "75%            0.038770           0.024507  ...              0.044165   \n",
              "max            0.145364           0.128301  ...              0.194616   \n",
              "\n",
              "       195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\n",
              "count           1213.000000           1213.000000           1213.000000   \n",
              "mean              -0.004938             -0.004378              0.001610   \n",
              "std                0.046536              0.042900              0.047424   \n",
              "min               -0.176523             -0.178688             -0.138048   \n",
              "25%               -0.033424             -0.033798             -0.030132   \n",
              "50%               -0.004683             -0.003724              0.000990   \n",
              "75%                0.024913              0.024007              0.032268   \n",
              "max                0.183152              0.180562              0.192015   \n",
              "\n",
              "       196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\n",
              "count           1213.000000           1213.000000           1213.000000   \n",
              "mean               0.115171              0.049984              0.058144   \n",
              "std                0.057128              0.051664              0.057674   \n",
              "min               -0.070094             -0.153540             -0.131455   \n",
              "25%                0.080291              0.015827              0.022316   \n",
              "50%                0.113640              0.052705              0.059151   \n",
              "75%                0.150524              0.082526              0.095192   \n",
              "max                0.375635              0.228748              0.322084   \n",
              "\n",
              "       197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \n",
              "count           1213.000000           1213.000000           1213.000000  \n",
              "mean               0.093527              0.089403              0.128946  \n",
              "std                0.054594              0.058036              0.058490  \n",
              "min               -0.085566             -0.204160             -0.083077  \n",
              "25%                0.059621              0.053224              0.090459  \n",
              "50%                0.093397              0.088612              0.127913  \n",
              "75%                0.127144              0.127613              0.166523  \n",
              "max                0.348153              0.267162              0.414304  \n",
              "\n",
              "[8 rows x 19900 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2888de96-8fb3-4837-9f16-6eafe5654d02\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0throw_1thcolumn</th>\n",
              "      <th>0throw_2thcolumn</th>\n",
              "      <th>0throw_3thcolumn</th>\n",
              "      <th>0throw_4thcolumn</th>\n",
              "      <th>0throw_5thcolumn</th>\n",
              "      <th>0throw_6thcolumn</th>\n",
              "      <th>0throw_7thcolumn</th>\n",
              "      <th>0throw_8thcolumn</th>\n",
              "      <th>0throw_9thcolumn</th>\n",
              "      <th>0throw_10thcolumn</th>\n",
              "      <th>...</th>\n",
              "      <th>195throw_196thcolumn</th>\n",
              "      <th>195throw_197thcolumn</th>\n",
              "      <th>195throw_198thcolumn</th>\n",
              "      <th>195throw_199thcolumn</th>\n",
              "      <th>196throw_197thcolumn</th>\n",
              "      <th>196throw_198thcolumn</th>\n",
              "      <th>196throw_199thcolumn</th>\n",
              "      <th>197throw_198thcolumn</th>\n",
              "      <th>197throw_199thcolumn</th>\n",
              "      <th>198throw_199thcolumn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "      <td>1213.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.060553</td>\n",
              "      <td>0.122315</td>\n",
              "      <td>0.060268</td>\n",
              "      <td>0.041287</td>\n",
              "      <td>0.069722</td>\n",
              "      <td>0.091007</td>\n",
              "      <td>0.066852</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.014128</td>\n",
              "      <td>-0.002914</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011075</td>\n",
              "      <td>-0.004938</td>\n",
              "      <td>-0.004378</td>\n",
              "      <td>0.001610</td>\n",
              "      <td>0.115171</td>\n",
              "      <td>0.049984</td>\n",
              "      <td>0.058144</td>\n",
              "      <td>0.093527</td>\n",
              "      <td>0.089403</td>\n",
              "      <td>0.128946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.064178</td>\n",
              "      <td>0.054026</td>\n",
              "      <td>0.057495</td>\n",
              "      <td>0.043491</td>\n",
              "      <td>0.044222</td>\n",
              "      <td>0.049189</td>\n",
              "      <td>0.046864</td>\n",
              "      <td>0.049046</td>\n",
              "      <td>0.038205</td>\n",
              "      <td>0.042462</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049632</td>\n",
              "      <td>0.046536</td>\n",
              "      <td>0.042900</td>\n",
              "      <td>0.047424</td>\n",
              "      <td>0.057128</td>\n",
              "      <td>0.051664</td>\n",
              "      <td>0.057674</td>\n",
              "      <td>0.054594</td>\n",
              "      <td>0.058036</td>\n",
              "      <td>0.058490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.183279</td>\n",
              "      <td>-0.059932</td>\n",
              "      <td>-0.145566</td>\n",
              "      <td>-0.127827</td>\n",
              "      <td>-0.072043</td>\n",
              "      <td>-0.079184</td>\n",
              "      <td>-0.105722</td>\n",
              "      <td>-0.164297</td>\n",
              "      <td>-0.137728</td>\n",
              "      <td>-0.148490</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.161666</td>\n",
              "      <td>-0.176523</td>\n",
              "      <td>-0.178688</td>\n",
              "      <td>-0.138048</td>\n",
              "      <td>-0.070094</td>\n",
              "      <td>-0.153540</td>\n",
              "      <td>-0.131455</td>\n",
              "      <td>-0.085566</td>\n",
              "      <td>-0.204160</td>\n",
              "      <td>-0.083077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.018482</td>\n",
              "      <td>0.086102</td>\n",
              "      <td>0.026548</td>\n",
              "      <td>0.014457</td>\n",
              "      <td>0.042462</td>\n",
              "      <td>0.057614</td>\n",
              "      <td>0.036934</td>\n",
              "      <td>-0.031358</td>\n",
              "      <td>-0.010635</td>\n",
              "      <td>-0.030538</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.021376</td>\n",
              "      <td>-0.033424</td>\n",
              "      <td>-0.033798</td>\n",
              "      <td>-0.030132</td>\n",
              "      <td>0.080291</td>\n",
              "      <td>0.015827</td>\n",
              "      <td>0.022316</td>\n",
              "      <td>0.059621</td>\n",
              "      <td>0.053224</td>\n",
              "      <td>0.090459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.058276</td>\n",
              "      <td>0.123220</td>\n",
              "      <td>0.061339</td>\n",
              "      <td>0.043246</td>\n",
              "      <td>0.067066</td>\n",
              "      <td>0.086494</td>\n",
              "      <td>0.067247</td>\n",
              "      <td>0.002549</td>\n",
              "      <td>0.016130</td>\n",
              "      <td>-0.002604</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010254</td>\n",
              "      <td>-0.004683</td>\n",
              "      <td>-0.003724</td>\n",
              "      <td>0.000990</td>\n",
              "      <td>0.113640</td>\n",
              "      <td>0.052705</td>\n",
              "      <td>0.059151</td>\n",
              "      <td>0.093397</td>\n",
              "      <td>0.088612</td>\n",
              "      <td>0.127913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.100103</td>\n",
              "      <td>0.154518</td>\n",
              "      <td>0.099056</td>\n",
              "      <td>0.068408</td>\n",
              "      <td>0.096504</td>\n",
              "      <td>0.119404</td>\n",
              "      <td>0.095117</td>\n",
              "      <td>0.031053</td>\n",
              "      <td>0.038770</td>\n",
              "      <td>0.024507</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044165</td>\n",
              "      <td>0.024913</td>\n",
              "      <td>0.024007</td>\n",
              "      <td>0.032268</td>\n",
              "      <td>0.150524</td>\n",
              "      <td>0.082526</td>\n",
              "      <td>0.095192</td>\n",
              "      <td>0.127144</td>\n",
              "      <td>0.127613</td>\n",
              "      <td>0.166523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.321522</td>\n",
              "      <td>0.390895</td>\n",
              "      <td>0.278429</td>\n",
              "      <td>0.189825</td>\n",
              "      <td>0.317500</td>\n",
              "      <td>0.316811</td>\n",
              "      <td>0.270018</td>\n",
              "      <td>0.168196</td>\n",
              "      <td>0.145364</td>\n",
              "      <td>0.128301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.194616</td>\n",
              "      <td>0.183152</td>\n",
              "      <td>0.180562</td>\n",
              "      <td>0.192015</td>\n",
              "      <td>0.375635</td>\n",
              "      <td>0.228748</td>\n",
              "      <td>0.322084</td>\n",
              "      <td>0.348153</td>\n",
              "      <td>0.267162</td>\n",
              "      <td>0.414304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 19900 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2888de96-8fb3-4837-9f16-6eafe5654d02')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2888de96-8fb3-4837-9f16-6eafe5654d02 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2888de96-8fb3-4837-9f16-6eafe5654d02');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a396234d-1982-4eeb-95ea-792a9edab90f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a396234d-1982-4eeb-95ea-792a9edab90f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a396234d-1982-4eeb-95ea-792a9edab90f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcm.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "F6paWgMU_Ti7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2a8c7d-cc3c-4e8d-cf7b-df4c37c76ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcm.head()"
      ],
      "metadata": {
        "id": "bfGS0noEBaha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "21f05e85-7dde-4992-e5fc-c8dda168a75d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  participant_id  0throw_1thcolumn  0throw_2thcolumn  0throw_3thcolumn  \\\n",
              "0   70z8Q2xdTXM3          0.093473          0.146902          0.067893   \n",
              "1   WHWymJu6zNZi          0.029580          0.179323          0.112933   \n",
              "2   4PAQp1M6EyAo         -0.051580          0.139734          0.068295   \n",
              "3   obEacy4Of68I          0.016273          0.204702          0.115980   \n",
              "4   s7WzzDcmDOhF          0.065771          0.098714          0.097604   \n",
              "\n",
              "   0throw_4thcolumn  0throw_5thcolumn  0throw_6thcolumn  0throw_7thcolumn  \\\n",
              "0          0.015141          0.070221          0.063997          0.055382   \n",
              "1          0.038291          0.104899          0.064250          0.008488   \n",
              "2          0.046991          0.111085          0.026978          0.151377   \n",
              "3          0.043103          0.056431          0.057615          0.055773   \n",
              "4          0.112988          0.071139          0.085607          0.019392   \n",
              "\n",
              "   0throw_8thcolumn  0throw_9thcolumn  ...  195throw_196thcolumn  \\\n",
              "0         -0.035335          0.068583  ...              0.003404   \n",
              "1          0.077505         -0.004750  ...             -0.008409   \n",
              "2          0.021198          0.083721  ...              0.053245   \n",
              "3          0.075030          0.001033  ...             -0.023918   \n",
              "4         -0.036403         -0.020375  ...              0.066439   \n",
              "\n",
              "   195throw_197thcolumn  195throw_198thcolumn  195throw_199thcolumn  \\\n",
              "0             -0.010359             -0.050968             -0.014365   \n",
              "1             -0.008479              0.020891              0.017754   \n",
              "2             -0.028003              0.028773              0.024556   \n",
              "3             -0.005356              0.018607              0.016193   \n",
              "4             -0.076680             -0.047530             -0.031443   \n",
              "\n",
              "   196throw_197thcolumn  196throw_198thcolumn  196throw_199thcolumn  \\\n",
              "0              0.128066              0.112646             -0.058980   \n",
              "1              0.094040              0.035141              0.032537   \n",
              "2              0.166343              0.058925              0.035485   \n",
              "3              0.072955              0.130135              0.056120   \n",
              "4              0.221213              0.007343              0.005763   \n",
              "\n",
              "   197throw_198thcolumn  197throw_199thcolumn  198throw_199thcolumn  \n",
              "0              0.028228              0.133582              0.143372  \n",
              "1              0.075007              0.115350              0.138200  \n",
              "2              0.063661              0.042862              0.162162  \n",
              "3              0.084784              0.114148              0.190584  \n",
              "4              0.083820              0.079582              0.067269  \n",
              "\n",
              "[5 rows x 19901 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b228564-9cf4-4218-a404-1029f5cf9cfa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>0throw_1thcolumn</th>\n",
              "      <th>0throw_2thcolumn</th>\n",
              "      <th>0throw_3thcolumn</th>\n",
              "      <th>0throw_4thcolumn</th>\n",
              "      <th>0throw_5thcolumn</th>\n",
              "      <th>0throw_6thcolumn</th>\n",
              "      <th>0throw_7thcolumn</th>\n",
              "      <th>0throw_8thcolumn</th>\n",
              "      <th>0throw_9thcolumn</th>\n",
              "      <th>...</th>\n",
              "      <th>195throw_196thcolumn</th>\n",
              "      <th>195throw_197thcolumn</th>\n",
              "      <th>195throw_198thcolumn</th>\n",
              "      <th>195throw_199thcolumn</th>\n",
              "      <th>196throw_197thcolumn</th>\n",
              "      <th>196throw_198thcolumn</th>\n",
              "      <th>196throw_199thcolumn</th>\n",
              "      <th>197throw_198thcolumn</th>\n",
              "      <th>197throw_199thcolumn</th>\n",
              "      <th>198throw_199thcolumn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>70z8Q2xdTXM3</td>\n",
              "      <td>0.093473</td>\n",
              "      <td>0.146902</td>\n",
              "      <td>0.067893</td>\n",
              "      <td>0.015141</td>\n",
              "      <td>0.070221</td>\n",
              "      <td>0.063997</td>\n",
              "      <td>0.055382</td>\n",
              "      <td>-0.035335</td>\n",
              "      <td>0.068583</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>-0.010359</td>\n",
              "      <td>-0.050968</td>\n",
              "      <td>-0.014365</td>\n",
              "      <td>0.128066</td>\n",
              "      <td>0.112646</td>\n",
              "      <td>-0.058980</td>\n",
              "      <td>0.028228</td>\n",
              "      <td>0.133582</td>\n",
              "      <td>0.143372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WHWymJu6zNZi</td>\n",
              "      <td>0.029580</td>\n",
              "      <td>0.179323</td>\n",
              "      <td>0.112933</td>\n",
              "      <td>0.038291</td>\n",
              "      <td>0.104899</td>\n",
              "      <td>0.064250</td>\n",
              "      <td>0.008488</td>\n",
              "      <td>0.077505</td>\n",
              "      <td>-0.004750</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008409</td>\n",
              "      <td>-0.008479</td>\n",
              "      <td>0.020891</td>\n",
              "      <td>0.017754</td>\n",
              "      <td>0.094040</td>\n",
              "      <td>0.035141</td>\n",
              "      <td>0.032537</td>\n",
              "      <td>0.075007</td>\n",
              "      <td>0.115350</td>\n",
              "      <td>0.138200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4PAQp1M6EyAo</td>\n",
              "      <td>-0.051580</td>\n",
              "      <td>0.139734</td>\n",
              "      <td>0.068295</td>\n",
              "      <td>0.046991</td>\n",
              "      <td>0.111085</td>\n",
              "      <td>0.026978</td>\n",
              "      <td>0.151377</td>\n",
              "      <td>0.021198</td>\n",
              "      <td>0.083721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.053245</td>\n",
              "      <td>-0.028003</td>\n",
              "      <td>0.028773</td>\n",
              "      <td>0.024556</td>\n",
              "      <td>0.166343</td>\n",
              "      <td>0.058925</td>\n",
              "      <td>0.035485</td>\n",
              "      <td>0.063661</td>\n",
              "      <td>0.042862</td>\n",
              "      <td>0.162162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>obEacy4Of68I</td>\n",
              "      <td>0.016273</td>\n",
              "      <td>0.204702</td>\n",
              "      <td>0.115980</td>\n",
              "      <td>0.043103</td>\n",
              "      <td>0.056431</td>\n",
              "      <td>0.057615</td>\n",
              "      <td>0.055773</td>\n",
              "      <td>0.075030</td>\n",
              "      <td>0.001033</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023918</td>\n",
              "      <td>-0.005356</td>\n",
              "      <td>0.018607</td>\n",
              "      <td>0.016193</td>\n",
              "      <td>0.072955</td>\n",
              "      <td>0.130135</td>\n",
              "      <td>0.056120</td>\n",
              "      <td>0.084784</td>\n",
              "      <td>0.114148</td>\n",
              "      <td>0.190584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s7WzzDcmDOhF</td>\n",
              "      <td>0.065771</td>\n",
              "      <td>0.098714</td>\n",
              "      <td>0.097604</td>\n",
              "      <td>0.112988</td>\n",
              "      <td>0.071139</td>\n",
              "      <td>0.085607</td>\n",
              "      <td>0.019392</td>\n",
              "      <td>-0.036403</td>\n",
              "      <td>-0.020375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066439</td>\n",
              "      <td>-0.076680</td>\n",
              "      <td>-0.047530</td>\n",
              "      <td>-0.031443</td>\n",
              "      <td>0.221213</td>\n",
              "      <td>0.007343</td>\n",
              "      <td>0.005763</td>\n",
              "      <td>0.083820</td>\n",
              "      <td>0.079582</td>\n",
              "      <td>0.067269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 19901 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b228564-9cf4-4218-a404-1029f5cf9cfa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2b228564-9cf4-4218-a404-1029f5cf9cfa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2b228564-9cf4-4218-a404-1029f5cf9cfa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e650a74-b687-4458-a3dd-01bec35b0f36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e650a74-b687-4458-a3dd-01bec35b0f36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e650a74-b687-4458-a3dd-01bec35b0f36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "fcm"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I was going to graph below, but each participants fcms need to be a numpy array for this to work so it doesn't run for now."
      ],
      "metadata": {
        "id": "os2RS7e1EVqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example data\n",
        "# Assume `matrices` is a list of connectivity matrices (2D arrays) for all individuals\n",
        "# Assume `labels` is a list of binary labels (0 or 1) corresponding to each individual\n",
        "\n",
        "# Separate matrices into two groups based on labels\n",
        "group_0 = [graph_fcm[i] for i in range(len(graph_fcm)) if graph_fcm.ADHD_Outcome[i] == 0]\n",
        "group_1 = [graph_fcm[i] for i in range(len(graph_fcm)) if graph_fcm.ADHD_Outcome[i] == 1]\n",
        "\n",
        "# Compute average connectivity matrices for each group\n",
        "avg_matrix_0 = np.mean(group_0, axis=0)\n",
        "avg_matrix_1 = np.mean(group_1, axis=0)\n",
        "\n",
        "# Visualize the average matrices\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Plot group 0\n",
        "sns.heatmap(avg_matrix_0, ax=axes[0], cmap=\"coolwarm\", vmin=0, vmax=1, square=True, cbar=True)\n",
        "axes[0].set_title(\"Group 0 (Label = 0)\")\n",
        "\n",
        "# Plot group 1\n",
        "sns.heatmap(avg_matrix_1, ax=axes[1], cmap=\"coolwarm\", vmin=0, vmax=1, square=True, cbar=True)\n",
        "axes[1].set_title(\"Group 1 (Label = 1)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Optional: Compute and visualize the difference between the two groups\n",
        "difference_matrix = avg_matrix_1 - avg_matrix_0\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(difference_matrix, cmap=\"coolwarm\", center=0, square=True, cbar=True)\n",
        "plt.title(\"Difference (Group 1 - Group 0)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Xn4WLYLCkq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_fcm.columns"
      ],
      "metadata": {
        "id": "RYBkvmQkDsjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10565a40-e976-42d4-b5ff-77ce9669297c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['participant_id', '0throw_1thcolumn', '0throw_2thcolumn',\n",
              "       '0throw_3thcolumn', '0throw_4thcolumn', '0throw_5thcolumn',\n",
              "       '0throw_6thcolumn', '0throw_7thcolumn', '0throw_8thcolumn',\n",
              "       '0throw_9thcolumn',\n",
              "       ...\n",
              "       '195throw_198thcolumn', '195throw_199thcolumn', '196throw_197thcolumn',\n",
              "       '196throw_198thcolumn', '196throw_199thcolumn', '197throw_198thcolumn',\n",
              "       '197throw_199thcolumn', '198throw_199thcolumn', 'ADHD_Outcome',\n",
              "       'Sex_F'],\n",
              "      dtype='object', length=19903)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(graph_fcm.isna().sum().sum()) #sum of missing values along all cols. shld be zero."
      ],
      "metadata": {
        "id": "fdeqQazdA9aX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892690b8-b373-40dc-dae1-35ae65397d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Data Exploration </h2>\n",
        "\n",
        "Doesn't seem to be missing any values. Checking the distribution of ADHD_Outcome and Sex_F."
      ],
      "metadata": {
        "id": "X6WHYlu8FIay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.countplot(x='ADHD_Outcome', data=graph_fcm)\n",
        "plt.title('Distribution of ADHD Outcome')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.countplot(x='Sex_F', data=graph_fcm)\n",
        "plt.title('Distribution of Sex (Female)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N4d7OWoDC6IZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "1f9282e2-4417-4195-9aba-13d5981f7986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
            "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok looks like there is still way more male ADHD data than female. We can consider training on only the female if the accuracy is bad there. Now graphing the average connectivity of the matrices"
      ],
      "metadata": {
        "id": "18D2MXk4GX8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Extract connectivity strength columns (excluding participant_id and ADHD_Outcome)\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
        "\n",
        "# Calculate the average connectivity strength for each connection\n",
        "average_connectivity = graph_fcm[connectivity_columns].mean()\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "average_connectivity.plot(kind='bar')\n",
        "plt.xlabel('Connection (Vertex Pair)')\n",
        "plt.ylabel('Average Connectivity Strength')\n",
        "plt.title('Average Connectivity Strengths Between Vertices')\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pKZis_X3DGeO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "b835e415-57d3-446a-fb6c-fb385b1ebf9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> FCM Graph Neural Network </h2>\n",
        "AKA the hard part. Having a hard time keeping it from crashing; should follow the example architecture very carefully because we're dealing with a lot of data."
      ],
      "metadata": {
        "id": "If-aKH0mfkUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GCN Summary"
      ],
      "metadata": {
        "id": "m0m85V7uliwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can't seem to better than 0.6851\n",
        "\n",
        "<h2> Google Collab Code </h2>\n",
        "\n",
        "Aka runnable version of above code\n",
        "\n",
        "| Label | Accuracy | Nodes |\n",
        "|-------|----------|-------|\n",
        "| ADHD  | 0.6851   | fully-connected |\n",
        "|Sex_F  | 0.6570   | fully-connected |\n",
        "| ADHD  | 0.8450   | half connected  |\n",
        "| Sex_F | 0.8195   | half connected  |\n",
        "\n",
        "### Class Weights to Minority\n",
        "\n",
        "| Label | Accuracy |\n",
        "|-------|----------|\n",
        "| ADHD  | 0.5      |\n",
        "\n",
        "\n",
        "### SMOTE - Oversampling minority\n",
        "\n",
        "\n",
        "| Label | Accuracy |\n",
        "|-------|----------|\n",
        "| ADHD  | 0.5      |\n",
        "|Sex_F  | 0.5      |\n",
        "\n",
        "### Different GCN\n",
        "\n",
        "| Label | Accuracy | Learning Rate |\n",
        "|-------|----------|---------------|\n",
        "| ADHD  | 0.6851   | 0.01          |\n",
        "| ADHD  | 0.6851   | 0.05          |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DbAeEcVsrBRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Collab Running Code\n",
        "Runs!\n",
        "Both have such high losses they are randomly guessing so.\n",
        "\n",
        "Predicting ADHD"
      ],
      "metadata": {
        "id": "6EQ3O1p-aoSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")"
      ],
      "metadata": {
        "id": "zc4iiEOBbL_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "a6sML1CRdhNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08db485b-5ad7-4cf0-94c4-b2fd9640fd5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6911\n",
            "Epoch 50, Loss: 0.6272\n",
            "Epoch 100, Loss: 0.6230\n",
            "Epoch 150, Loss: 0.6230\n",
            "Accuracy: 0.6851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Sex_F with same model as above"
      ],
      "metadata": {
        "id": "imsqRNwuayjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")"
      ],
      "metadata": {
        "id": "8kF_X0KMbSQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('ADHD_Outcome', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['Sex_F'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_f = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_f.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_f.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_f(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_f.eval()\n",
        "_, pred = model_f(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SAiqbrjanKC",
        "outputId": "71ba6f51-c9e9-40c0-b760-acfdcfc71f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6920\n",
            "Epoch 50, Loss: 0.6448\n",
            "Epoch 100, Loss: 0.6430\n",
            "Epoch 150, Loss: 0.6430\n",
            "Accuracy: 0.6570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Class Weights to Above Models\n",
        "\n",
        "To add more weight to minority classes (female and non-adhd) to see if it improves model accuracy because without it, the testing model just guessed not female and has adhd for every participant ;,(. unchanging loss means it's stuck in confusion"
      ],
      "metadata": {
        "id": "3UxFUxDxht3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ADHD_Outcome\n",
        "\n",
        "Basically same outcome so i didn't try it on Sex_f"
      ],
      "metadata": {
        "id": "d7MpABIJh9vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "from sklearn.utils.class_weight import compute_class_weight #for weightsi\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "#Weights\n",
        "#compute weights\n",
        "labels_np = labels.astype(int)\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(labels_np), y=labels_np)\n",
        "#convert to pytorch tensor and move to device\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights) #add argument to this to account for weights\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d82Awp5iBAz",
        "outputId": "890a01c7-2ae3-4f67-a916-336d0155bf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6932\n",
            "Epoch 50, Loss: 0.6932\n",
            "Epoch 100, Loss: 0.6931\n",
            "Epoch 150, Loss: 0.6931\n",
            "Accuracy: 0.6851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(Counter(pred.tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_luL5qaFuM9",
        "outputId": "e7c62be5-16c5-42f1-8b3a-dbad4bd19493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 954, 1: 259})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using oversampling of minority class\n",
        "\n",
        "Using SMOTE (Synthetic Minority Over-sampling Technique) (did even worse, also stuck)"
      ],
      "metadata": {
        "id": "sHz5jw_skpMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADHD outcome\n",
        "\n",
        "50% is worse bruh"
      ],
      "metadata": {
        "id": "FdeBHqBak48q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "########### BALANCING MINORITIES ###############\n",
        "# identifying minority class in tester (no ADHD is minority in training, might not be for tester but i doubt it, but we'll check anyways)\n",
        "minority_class = 0 if np.sum(labels == 1) > np.sum(labels == 0) else 1\n",
        "\n",
        "minority_indices = np.where(labels == minority_class)[0]\n",
        "majority_indices = np.where(labels != minority_class)[0]\n",
        "\n",
        "#ovesample minority bu duplicating them\n",
        "num_minority_needed = len(majority_indices) - len(minority_indices)\n",
        "oversampled_minority_indices = np.random.choice(minority_indices, num_minority_needed, replace=True)\n",
        "\n",
        "#combine all new duplicated min. with original where minority and majority class are balanced\n",
        "balanced_indices = np.concatenate([majority_indices, minority_indices, oversampled_minority_indices])\n",
        "\n",
        "# get new features and labels\n",
        "features_balanced = features[balanced_indices]\n",
        "labels_balanced = labels[balanced_indices]\n",
        "\n",
        "#################################################\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features_balanced.shape[0]  # CHANGED TO FATURED_BALANCED // Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device (change to featured_balanced)\n",
        "data = Data(\n",
        "    x=torch.tensor(features_balanced, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels_balanced, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "548i3k1bj6zO",
        "outputId": "51554232-86a1-4ede-a398-e5e8f3de5dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6932\n",
            "Epoch 50, Loss: 0.6931\n",
            "Epoch 100, Loss: 0.6931\n",
            "Epoch 150, Loss: 0.6931\n",
            "Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sex_f bc why not\n",
        "\n",
        "same result"
      ],
      "metadata": {
        "id": "5AwhGOMdqQWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('ADHD_Outcome', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['Sex_F'].values\n",
        "\n",
        "########### BALANCING MINORITIES ###############\n",
        "# identifying minority class in tester (no ADHD is minority in training, might not be for tester but i doubt it, but we'll check anyways)\n",
        "minority_class = 0 if np.sum(labels == 1) > np.sum(labels == 0) else 1\n",
        "\n",
        "minority_indices = np.where(labels == minority_class)[0]\n",
        "majority_indices = np.where(labels != minority_class)[0]\n",
        "\n",
        "#ovesample minority bu duplicating them\n",
        "num_minority_needed = len(majority_indices) - len(minority_indices)\n",
        "oversampled_minority_indices = np.random.choice(minority_indices, num_minority_needed, replace=True)\n",
        "\n",
        "#combine all new duplicated min. with original where minority and majority class are balanced\n",
        "balanced_indices = np.concatenate([majority_indices, minority_indices, oversampled_minority_indices])\n",
        "\n",
        "# get new features and labels\n",
        "features_balanced = features[balanced_indices]\n",
        "labels_balanced = labels[balanced_indices]\n",
        "\n",
        "#################################################\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features_balanced.shape[0]  # CHANGED TO FATURED_BALANCED // Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device (change to featured_balanced)\n",
        "data = Data(\n",
        "    x=torch.tensor(features_balanced, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels_balanced, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBpHJ6jQqPlX",
        "outputId": "3d934c36-7d8b-43a9-ad29-24c7d5a0050d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6935\n",
            "Epoch 50, Loss: 0.6932\n",
            "Epoch 100, Loss: 0.6931\n",
            "Epoch 150, Loss: 0.6931\n",
            "Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying more GCN Model\n",
        "\n",
        "More layers, BatchNorm, ReLU, and Dropout (prevent overfitting) (still stuck/guessing)"
      ],
      "metadata": {
        "id": "l7mP1r-rsuNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADHD_Outcome"
      ],
      "metadata": {
        "id": "s2KuHRKzs2sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels) #batch norm\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = torch.nn.Dropout(0.5) #dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.05\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4UmXwSNqwLi",
        "outputId": "b8d666d0-6781-4395-dc53-8417c8e93b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6931\n",
            "Epoch 50, Loss: 0.6230\n",
            "Epoch 100, Loss: 0.6230\n",
            "Epoch 150, Loss: 0.6230\n",
            "Accuracy: 0.6851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying Less Connected Graph\n",
        "\n",
        "half connected\n",
        "Overall: BETTER OUTCOME! .72 on submission\n",
        "\n",
        "1/3 connected\n",
        "Overall: Worse, 0.71 on submission\n",
        "\n",
        "ADHD Outcome\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "02FavhHhu1Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5))) #LITERALLY JUST DIVIDED IN HALF SO ITS NOT FULLY CONNECTED ITS HALF CONNECTED?\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thp2Uq2tu4bk",
        "outputId": "184ace06-4799-429b-a328-e42ab99c7f80"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.7029\n",
            "Epoch 50, Loss: 0.4586\n",
            "Epoch 100, Loss: 0.3809\n",
            "Epoch 150, Loss: 0.3373\n",
            "Accuracy: 0.8813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same model as above, but train test splitting the data. like in the submission, test accuracy is 70 ish, overfitting on training\n",
        "\n"
      ],
      "metadata": {
        "id": "dqeP4a0dIyR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (placeholder, adjust as needed)\n",
        "num_nodes = features.shape[0]\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/3), (int)(num_nodes/3))) #LITERALLY JUST DIVIDED IN HALF SO ITS NOT FULLY CONNECTED ITS HALF CONNECTED?\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Create train/test split indices\n",
        "train_idx, test_idx = train_test_split(np.arange(num_nodes), test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "train_mask[train_idx] = True\n",
        "test_mask[test_idx] = True\n",
        "\n",
        "# Add masks to the data object\n",
        "data.train_mask = train_mask.to(device)\n",
        "data.test_mask = test_mask.to(device)\n",
        "\n",
        "\n",
        "# Define the GCN model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Only train on train set\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation on test set\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "acc = correct / data.test_mask.sum().item()\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUrhzZVJIvAF",
        "outputId": "f68fb433-0be5-4b87-8b6c-7b879b47a081"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6817\n",
            "Epoch 50, Loss: 0.3798\n",
            "Epoch 100, Loss: 0.3789\n",
            "Epoch 150, Loss: 0.3755\n",
            "Test Accuracy: 0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sex_F"
      ],
      "metadata": {
        "id": "4vWHP308zG2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('ADHD_Outcome', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['Sex_F'].values\n",
        "\n",
        "# Create an adjacency matrix (replace with actual adjacency if available)\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5)))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_f = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_f.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_f.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_f(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_f.eval()\n",
        "_, pred = model_f(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShkMqNQrzGcT",
        "outputId": "e74c15a9-c2cd-4460-8807-badda7b6b913"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6963\n",
            "Epoch 50, Loss: 0.5400\n",
            "Epoch 100, Loss: 0.5097\n",
            "Epoch 150, Loss: 0.5193\n",
            "Accuracy: 0.8607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "doing the same here - adding train/test checking on this model. looks like it's overfitting on the training, since training is 87% but test is only 62%"
      ],
      "metadata": {
        "id": "0ooj27lTJc0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'ADHD_Outcome' column\n",
        "graph_fcm = graph_fcm.drop('ADHD_Outcome', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['Sex_F'].values\n",
        "\n",
        "# Create an adjacency matrix (placeholder, adjust as needed)\n",
        "num_nodes = features.shape[0]\n",
        "adjacency_matrix = np.ones((num_nodes, num_nodes))  # Fully connected\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Create train/test split indices\n",
        "train_idx, test_idx = train_test_split(np.arange(num_nodes), test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "train_mask[train_idx] = True\n",
        "test_mask[test_idx] = True\n",
        "\n",
        "# Add masks to the data object\n",
        "data.train_mask = train_mask.to(device)\n",
        "data.test_mask = test_mask.to(device)\n",
        "\n",
        "\n",
        "# Define the GCN model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: Female (1) and Male (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_f = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_f.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_f.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_f(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Only train on train set\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation on test set\n",
        "model_f.eval()\n",
        "_, pred = model_f(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "acc = correct / data.test_mask.sum().item()\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfHt7K6UJYyF",
        "outputId": "bf014c80-e358-465c-8017-0d82f1950819"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 0.6911\n",
            "Epoch 50, Loss: 0.6409\n",
            "Epoch 100, Loss: 0.6384\n",
            "Epoch 150, Loss: 0.6384\n",
            "Test Accuracy: 0.6296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADHD Parameters with Optuna (don't need to rerun)"
      ],
      "metadata": {
        "id": "Qc-cDjDPMtap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> getting the hyperparameters"
      ],
      "metadata": {
        "id": "B6IEqTW5NKtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OxUa5-YMzqL",
        "outputId": "c03804cc-3578-4c38-e5ca-799b171851ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome','Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    hidden_channels = trial.suggest_categorical('hidden_channels', [16, 32, 64, 128])\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
        "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
        "\n",
        "    class GCN(torch.nn.Module):\n",
        "        def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "            super().__init__()\n",
        "            self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "            self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        def forward(self, x, edge_index):\n",
        "            x = self.conv1(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=dropout_rate, training=self.training)\n",
        "            x = self.conv2(x, edge_index)\n",
        "            return F.log_softmax(x, dim=1)\n",
        "\n",
        "    # Initialize model and optimizer\n",
        "    model = GCN(data.num_features, hidden_channels, 2).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(100):  # Train for 100 epochs\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    _, pred = model(data.x, data.edge_index).max(dim=1)\n",
        "    correct = float(pred.eq(data.y).sum().item())\n",
        "    acc = correct / len(data.y)\n",
        "\n",
        "    return acc  # Optuna will maximize accuracy\n",
        "\n",
        "# Run the optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best hyperparameters:\", study.best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYpD368QM3jr",
        "outputId": "cb7e9a19-908a-40b1-d125-fb10935ef3e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-03 02:06:49,100] A new study created in memory with name: no-name-abc11bfe-8cd5-46f7-8a62-4a9aede266ba\n",
            "<ipython-input-31-b35fec2a0bb5>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-31-b35fec2a0bb5>:18: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-31-b35fec2a0bb5>:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-03 02:06:49,829] Trial 0 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.00021633938235848677, 'dropout_rate': 0.22806633854702552, 'weight_decay': 7.937180286936818e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:50,288] Trial 1 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.0011754687077643322, 'dropout_rate': 0.4361193321192408, 'weight_decay': 9.44789604787178e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:50,636] Trial 2 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0004365476347267617, 'dropout_rate': 0.39395772825010167, 'weight_decay': 0.0004512588655551924}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:50,972] Trial 3 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0010277865478074898, 'dropout_rate': 0.5765813312023266, 'weight_decay': 1.1137613955188023e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:51,571] Trial 4 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.0001555403525869421, 'dropout_rate': 0.29827143943128964, 'weight_decay': 3.2218100298910296e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:52,164] Trial 5 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.002840085366187574, 'dropout_rate': 0.34959986217821276, 'weight_decay': 0.00028274433998075126}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:52,758] Trial 6 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.00412344628757858, 'dropout_rate': 0.5548150931935631, 'weight_decay': 2.3229994570257414e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:53,363] Trial 7 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.0007238850873061881, 'dropout_rate': 0.2580497724879839, 'weight_decay': 0.0002784681032666771}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:54,346] Trial 8 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 128, 'learning_rate': 0.000905177655588712, 'dropout_rate': 0.5643399677685368, 'weight_decay': 1.1284774603360591e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:54,692] Trial 9 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0010841130623192381, 'dropout_rate': 0.27400494576234485, 'weight_decay': 0.00031937298484434616}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:55,104] Trial 10 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.00012183472510915615, 'dropout_rate': 0.20417111255515008, 'weight_decay': 3.2758215922135186e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:55,523] Trial 11 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.0003610339536704283, 'dropout_rate': 0.4776886872943681, 'weight_decay': 5.581589144529792e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:55,954] Trial 12 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.007493602766215545, 'dropout_rate': 0.4658063189435049, 'weight_decay': 8.50219994292673e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:56,937] Trial 13 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 128, 'learning_rate': 0.001888113413317792, 'dropout_rate': 0.437857975219328, 'weight_decay': 0.00010999225537248711}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:57,352] Trial 14 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.00021322785156053557, 'dropout_rate': 0.3686756395591519, 'weight_decay': 1.2828900784253196e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:57,968] Trial 15 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.0003117471167746351, 'dropout_rate': 0.3364609894437958, 'weight_decay': 1.3943117089404795e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:58,380] Trial 16 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.0020040861626913417, 'dropout_rate': 0.20352425803249602, 'weight_decay': 0.000865821555654798}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:06:59,389] Trial 17 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 128, 'learning_rate': 0.000580293931027935, 'dropout_rate': 0.5045971196932789, 'weight_decay': 0.00014016876274311943}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:00,008] Trial 18 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.00010283190292260865, 'dropout_rate': 0.4210887722940218, 'weight_decay': 3.0258559521257916e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:00,462] Trial 19 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.0002322897961362619, 'dropout_rate': 0.5160528588328834, 'weight_decay': 5.04705684227275e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:00,923] Trial 20 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.001338714495162762, 'dropout_rate': 0.307641612016452, 'weight_decay': 0.0001783647292120885}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:01,308] Trial 21 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.000493501719748014, 'dropout_rate': 0.3837730394485176, 'weight_decay': 0.0008774800829988629}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:01,724] Trial 22 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00042563776239273166, 'dropout_rate': 0.4288154682466638, 'weight_decay': 0.00039826088779175564}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:02,178] Trial 23 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00026063603855918527, 'dropout_rate': 0.24579142144967822, 'weight_decay': 0.0004582310714786096}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:02,628] Trial 24 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00017386725908004696, 'dropout_rate': 0.395888759084119, 'weight_decay': 7.6284359830568e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:02,985] Trial 25 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0006873193452696031, 'dropout_rate': 0.32875012229862455, 'weight_decay': 0.0001729376224219223}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:03,606] Trial 26 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.0014926374080553354, 'dropout_rate': 0.5187461564704693, 'weight_decay': 2.7421400290018594e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:04,614] Trial 27 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 128, 'learning_rate': 0.00039191547028977067, 'dropout_rate': 0.4610249223503598, 'weight_decay': 0.0006440212844273733}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:04,967] Trial 28 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0036889179743062163, 'dropout_rate': 0.4119844696780935, 'weight_decay': 0.0001708344210879233}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:05,594] Trial 29 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.0009308935790531879, 'dropout_rate': 0.3719820779275818, 'weight_decay': 5.719835432769342e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:06,013] Trial 30 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.0005620189293064251, 'dropout_rate': 0.5840893476056268, 'weight_decay': 2.220916771798166e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:06,370] Trial 31 finished with value: 0.8961253091508656 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00014966357719262222, 'dropout_rate': 0.5982561329895549, 'weight_decay': 8.414423496278823e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:06,725] Trial 32 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0022159802511557626, 'dropout_rate': 0.3113594898618407, 'weight_decay': 4.366142387641457e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:07,084] Trial 33 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0007074147400273308, 'dropout_rate': 0.5459578278991197, 'weight_decay': 4.8459269867554184e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:07,778] Trial 34 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.001222179046423786, 'dropout_rate': 0.2293038754323084, 'weight_decay': 1.7608518004713652e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:08,640] Trial 35 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.0002946650096976898, 'dropout_rate': 0.283643780374629, 'weight_decay': 8.387866550895577e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:08,998] Trial 36 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0009193338439689414, 'dropout_rate': 0.35999740608299885, 'weight_decay': 0.00026011223984748313}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:09,619] Trial 37 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.0001907348868893815, 'dropout_rate': 0.5432966578715452, 'weight_decay': 2.8223327769563014e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:09,971] Trial 38 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0029705958815193063, 'dropout_rate': 0.49063480792807174, 'weight_decay': 7.455223857417687e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:10,988] Trial 39 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 128, 'learning_rate': 0.0016329334136163062, 'dropout_rate': 0.45447801685230815, 'weight_decay': 1.4996256618803085e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:11,403] Trial 40 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.0007484226475475699, 'dropout_rate': 0.5703287631232881, 'weight_decay': 0.0002589313002371286}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:12,027] Trial 41 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.00014362053213096338, 'dropout_rate': 0.28542421329762147, 'weight_decay': 2.6137936312056775e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:12,657] Trial 42 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.00011958353811120829, 'dropout_rate': 0.22564201465112457, 'weight_decay': 3.7807243547834387e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:13,321] Trial 43 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.008578741450188332, 'dropout_rate': 0.2602067011577731, 'weight_decay': 1.5539744640785295e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:14,010] Trial 44 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.00029763053546528166, 'dropout_rate': 0.33829080081940105, 'weight_decay': 4.025922252606406e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:14,515] Trial 45 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.0011625694290600835, 'dropout_rate': 0.2663077390675698, 'weight_decay': 0.00010741851298515253}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:15,201] Trial 46 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 64, 'learning_rate': 0.005387069298350079, 'dropout_rate': 0.30699868020010584, 'weight_decay': 8.547229964043962e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:16,246] Trial 47 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 128, 'learning_rate': 0.00022908858338102894, 'dropout_rate': 0.44269812827990696, 'weight_decay': 1.563614684573472e-05}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:16,675] Trial 48 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 32, 'learning_rate': 0.0004597617570121393, 'dropout_rate': 0.23669693786136878, 'weight_decay': 6.358223691815144e-06}. Best is trial 0 with value: 0.9060181368507831.\n",
            "[I 2025-03-03 02:07:17,039] Trial 49 finished with value: 0.9060181368507831 and parameters: {'hidden_channels': 16, 'learning_rate': 0.000350117976744812, 'dropout_rate': 0.21092598240213345, 'weight_decay': 6.275427978583e-05}. Best is trial 0 with value: 0.9060181368507831.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'hidden_channels': 64, 'learning_rate': 0.00021633938235848677, 'dropout_rate': 0.22806633854702552, 'weight_decay': 7.937180286936818e-05}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ADHD model with optuna optimized (90% train)"
      ],
      "metadata": {
        "id": "KoX-ZIMkNz-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome','Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Define the GCN model with best hyperparameters\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Create an adjacency matrix (adjust as needed)\n",
        "num_nodes = features.shape[0]\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/3), (int)(num_nodes/3)))  # Example adjacency structure\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_channels = 32\n",
        "learning_rate = 0.000169\n",
        "dropout_rate = 0.394\n",
        "weight_decay = 5.93e-05\n",
        "epochs = 200\n",
        "patience = 10  # Early stopping patience\n",
        "\n",
        "# Initialize model\n",
        "adhd_model = GCN(data.num_features, hidden_channels, 2, dropout_rate).to(device)\n",
        "optimizer = torch.optim.Adam(adhd_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Early stopping variables\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "# Training loop with early stopping\n",
        "adhd_model.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = adhd_model(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Early stopping condition\n",
        "    if loss.item() < best_val_loss:\n",
        "        best_val_loss = loss.item()\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "adhd_model.eval()\n",
        "_, pred = adhd_model(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Train Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TufZY7_KNXri",
        "outputId": "37962246-c7dc-4c26-9cae-e83ddc29cdcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7020\n",
            "Epoch 50, Loss: 0.4000\n",
            "Epoch 100, Loss: 0.2906\n",
            "Epoch 150, Loss: 0.2470\n",
            "Train Accuracy: 0.9060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_cpu = pred.cpu()\n",
        "\n",
        "# Convert the tensor to a NumPy array\n",
        "array = pred_cpu.numpy()\n",
        "\n",
        "# Create a DataFrame from the NumPy array\n",
        "df = pd.DataFrame(array, columns=['Values'])\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "BliPf-S72Na_",
        "outputId": "4031d3f4-147b-43fd-d302-f730aaaa02d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Values\n",
              "count  1213.000000\n",
              "mean      0.779060\n",
              "std       0.415051\n",
              "min       0.000000\n",
              "25%       1.000000\n",
              "50%       1.000000\n",
              "75%       1.000000\n",
              "max       1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-242a3882-42da-4f04-a5e4-7772d3d5175e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1213.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.779060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.415051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-242a3882-42da-4f04-a5e4-7772d3d5175e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-242a3882-42da-4f04-a5e4-7772d3d5175e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-242a3882-42da-4f04-a5e4-7772d3d5175e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e84bd24a-ba30-4e5c-abce-86b32e087578\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e84bd24a-ba30-4e5c-abce-86b32e087578')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e84bd24a-ba30-4e5c-abce-86b32e087578 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Values\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 428.59807472416094,\n        \"min\": 0.0,\n        \"max\": 1213.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7790601813685079,\n          1.0,\n          0.4150511207596778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ADHD model testing generalization (incomplete)"
      ],
      "metadata": {
        "id": "2HI2n7fYOk19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix (adjust as needed)\n",
        "num_nodes = features.shape[0]\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/3), (int)(num_nodes/3)))  # Example adjacency structure\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long),\n",
        "    y=torch.tensor(labels, dtype=torch.long)\n",
        ")\n",
        "\n",
        "# Create train/test split indices\n",
        "train_idx, test_idx = train_test_split(np.arange(num_nodes), test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "train_mask[train_idx] = True\n",
        "test_mask[test_idx] = True\n",
        "\n",
        "# Add masks to the data object\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "# Define the GCN model with best hyperparameters\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_channels = 32\n",
        "learning_rate = 0.000169\n",
        "dropout_rate = 0.394\n",
        "weight_decay = 5.93e-05\n",
        "epochs = 200\n",
        "patience = 10  # Early stopping patience\n",
        "\n",
        "# Initialize model\n",
        "model = GCN(data.num_features, hidden_channels, 2, dropout_rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Early stopping variables\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "# Training loop with early stopping\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Only train on train set\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Early stopping condition\n",
        "    if loss.item() < best_val_loss:\n",
        "        best_val_loss = loss.item()\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation on test set\n",
        "model.eval()\n",
        "_, pred = model(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "acc = correct / data.test_mask.sum().item()\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcmSgS7OOjTE",
        "outputId": "c974ea7f-29e2-4e68-b792-5ce86ff31e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7102\n",
            "Epoch 50, Loss: 0.3770\n",
            "Epoch 100, Loss: 0.2727\n",
            "Epoch 150, Loss: 0.2382\n",
            "Test Accuracy: 0.7037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optuna predicting Sex_F (don't need to rerun)"
      ],
      "metadata": {
        "id": "qcO21_0WwxlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome','Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['Sex_F'].values\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    hidden_channels = trial.suggest_categorical('hidden_channels', [16, 32, 64, 128])\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
        "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
        "\n",
        "    class GCN(torch.nn.Module):\n",
        "        def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "            super().__init__()\n",
        "            self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "            self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        def forward(self, x, edge_index):\n",
        "            x = self.conv1(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=dropout_rate, training=self.training)\n",
        "            x = self.conv2(x, edge_index)\n",
        "            return F.log_softmax(x, dim=1)\n",
        "\n",
        "    # Initialize model and optimizer\n",
        "    model = GCN(data.num_features, hidden_channels, 2).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(100):  # Train for 100 epochs\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    _, pred = model(data.x, data.edge_index).max(dim=1)\n",
        "    correct = float(pred.eq(data.y).sum().item())\n",
        "    acc = correct / len(data.y)\n",
        "\n",
        "    return acc  # Optuna will maximize accuracy\n",
        "\n",
        "# Run the optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best hyperparameters:\", study.best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tR5G01Vjwlix",
        "outputId": "757a8a19-6c38-4345-9aa6-5bd85fd481ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-03 02:31:38,925] A new study created in memory with name: no-name-1226dcc8-248b-4111-81d3-98643a9479d6\n",
            "<ipython-input-50-7f1d702f086d>:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-50-7f1d702f086d>:18: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-50-7f1d702f086d>:19: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-03 02:31:39,273] Trial 0 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00036965175460554355, 'dropout_rate': 0.5260931581573112, 'weight_decay': 0.00014774587713524726}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:39,627] Trial 1 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00044474403949133225, 'dropout_rate': 0.5192193810621997, 'weight_decay': 1.6550176917545588e-05}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:40,609] Trial 2 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 128, 'learning_rate': 0.003064776368472588, 'dropout_rate': 0.3539535409203919, 'weight_decay': 1.8490967356500734e-05}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:41,020] Trial 3 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 32, 'learning_rate': 0.00019184672193363746, 'dropout_rate': 0.4500435649410247, 'weight_decay': 0.0007182168687212274}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:41,431] Trial 4 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 32, 'learning_rate': 0.00045349963996638577, 'dropout_rate': 0.214475010356127, 'weight_decay': 2.8884391298354385e-05}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:41,847] Trial 5 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 32, 'learning_rate': 0.003583076288573087, 'dropout_rate': 0.4003853375293025, 'weight_decay': 5.36601683570694e-06}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:42,256] Trial 6 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 32, 'learning_rate': 0.000607385120041463, 'dropout_rate': 0.5878404458060538, 'weight_decay': 2.4329185005205166e-05}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:42,614] Trial 7 finished with value: 0.8821104699093157 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00013308390242991846, 'dropout_rate': 0.5753368710168787, 'weight_decay': 0.0002053084277451193}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:43,024] Trial 8 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 32, 'learning_rate': 0.0005110732821991913, 'dropout_rate': 0.3674356244705891, 'weight_decay': 1.226420605477521e-06}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:43,435] Trial 9 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 32, 'learning_rate': 0.005858354948576827, 'dropout_rate': 0.3910132793902097, 'weight_decay': 0.0009351006573587936}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:44,067] Trial 10 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 64, 'learning_rate': 0.0016623622221376934, 'dropout_rate': 0.5015817471506907, 'weight_decay': 0.00016526983574631713}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:44,428] Trial 11 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00025378459548023, 'dropout_rate': 0.5092469138388224, 'weight_decay': 0.00013502208065796302}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:44,799] Trial 12 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0011365634577209305, 'dropout_rate': 0.5260642705965574, 'weight_decay': 6.201289886295616e-06}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:45,161] Trial 13 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0003531442716170102, 'dropout_rate': 0.46319118161957656, 'weight_decay': 9.235063275652282e-05}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:45,528] Trial 14 finished with value: 0.887881286067601 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00011050682063469171, 'dropout_rate': 0.28945364646500593, 'weight_decay': 6.495511988179212e-05}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:46,556] Trial 15 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 128, 'learning_rate': 0.0011091541279408983, 'dropout_rate': 0.5445110052548734, 'weight_decay': 8.332352222963565e-06}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:47,180] Trial 16 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 64, 'learning_rate': 0.0007629284596036339, 'dropout_rate': 0.4650058171879866, 'weight_decay': 0.00038535795543895594}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:47,619] Trial 17 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 16, 'learning_rate': 0.0002611874199575579, 'dropout_rate': 0.4272791868770103, 'weight_decay': 5.56918580813815e-05}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:48,026] Trial 18 finished with value: 0.8920032976092334 and parameters: {'hidden_channels': 16, 'learning_rate': 0.00016902165328363256, 'dropout_rate': 0.5533079235277935, 'weight_decay': 2.333018496793099e-06}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:48,427] Trial 19 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 16, 'learning_rate': 0.001823490280400422, 'dropout_rate': 0.31264579094373796, 'weight_decay': 1.0151196425927823e-05}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:49,544] Trial 20 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 128, 'learning_rate': 0.0003306700937975511, 'dropout_rate': 0.49745382348365197, 'weight_decay': 0.00040339155311925706}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[I 2025-03-03 02:31:50,589] Trial 21 finished with value: 0.8928276999175597 and parameters: {'hidden_channels': 128, 'learning_rate': 0.003403015353075276, 'dropout_rate': 0.34481335304624033, 'weight_decay': 1.4092556565077965e-05}. Best is trial 0 with value: 0.8928276999175597.\n",
            "[W 2025-03-03 02:31:50,675] Trial 22 failed with parameters: {'hidden_channels': 128, 'learning_rate': 0.0022672204273227153, 'dropout_rate': 0.2663018766864531, 'weight_decay': 1.7509678172492655e-05} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"<ipython-input-50-7f1d702f086d>\", line 43, in objective\n",
            "    out = model(data.x, data.edge_index)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-50-7f1d702f086d>\", line 31, in forward\n",
            "    x = self.conv2(x, edge_index)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\", line 241, in forward\n",
            "    edge_index, edge_weight = gcn_norm(  # yapf: disable\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\", line 99, in gcn_norm\n",
            "    edge_index, edge_weight = add_remaining_self_loops(\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/loop.py\", line 652, in add_remaining_self_loops\n",
            "    if not torch.jit.is_scripting() and isinstance(edge_index, EdgeIndex):\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_jit_internal.py\", line 103, in is_scripting\n",
            "    def is_scripting() -> bool:\n",
            "    \n",
            "KeyboardInterrupt\n",
            "[W 2025-03-03 02:31:50,681] Trial 22 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-7f1d702f086d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Run the optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Print best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-7f1d702f086d>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Train for 100 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-7f1d702f086d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         edge_index, edge_weight = add_remaining_self_loops(\n\u001b[0m\u001b[1;32m    100\u001b[0m             edge_index, edge_weight, fill_value, num_nodes)\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/utils/loop.py\u001b[0m in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdgeIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m         \u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_undirected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_undirected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mis_scripting\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     r\"\"\"\n\u001b[1;32m    105\u001b[0m     \u001b[0mFunction\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompilation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sex_F model with optuna optimized (89% train)"
      ],
      "metadata": {
        "id": "bXely-ewzkrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome','Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['Sex_F'].values\n",
        "\n",
        "# Define the GCN model with best hyperparameters\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Create an adjacency matrix (adjust as needed)\n",
        "num_nodes = features.shape[0]\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/3), (int)(num_nodes/3)))  # Example adjacency structure\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Hyperparameters\n",
        "hidden_channels = 16\n",
        "learning_rate = 0.00964833390349095\n",
        "dropout_rate = 0.4728723120058732\n",
        "weight_decay = 0.00017202291701416884\n",
        "epochs = 200\n",
        "patience = 10  # Early stopping patience\n",
        "\n",
        "# Initialize model\n",
        "sex_f_model = GCN(data.num_features, hidden_channels, 2, dropout_rate).to(device)\n",
        "optimizer = torch.optim.Adam(sex_f_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Early stopping variables\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "# Training loop with early stopping\n",
        "sex_f_model.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = sex_f_model(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Early stopping condition\n",
        "    if loss.item() < best_val_loss:\n",
        "        best_val_loss = loss.item()\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch}\")\n",
        "        break\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "sex_f_model.eval()\n",
        "_, pred = sex_f_model(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Train Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNiwd37RwwQW",
        "outputId": "a819866a-6be9-4a89-fa54-4877fb594fe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7099\n",
            "Epoch 50, Loss: 0.4333\n",
            "Early stopping at epoch 89\n",
            "Train Accuracy: 0.8928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_cpu = pred.cpu()\n",
        "\n",
        "# Convert the tensor to a NumPy array\n",
        "array = pred_cpu.numpy()\n",
        "\n",
        "# Create a DataFrame from the NumPy array\n",
        "df = pd.DataFrame(array, columns=['Values'])\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "zAW5tGoU3EkZ",
        "outputId": "f235bf6d-4f19-42ca-afd1-317254d2b92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Values\n",
              "count  1213.000000\n",
              "mean      0.235779\n",
              "std       0.424660\n",
              "min       0.000000\n",
              "25%       0.000000\n",
              "50%       0.000000\n",
              "75%       0.000000\n",
              "max       1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5df6c841-6fb9-4f83-96b0-314fd4a4e30f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1213.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.235779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.424660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5df6c841-6fb9-4f83-96b0-314fd4a4e30f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5df6c841-6fb9-4f83-96b0-314fd4a4e30f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5df6c841-6fb9-4f83-96b0-314fd4a4e30f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab776d86-4ea1-401f-98df-c9d1e4801ac7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab776d86-4ea1-401f-98df-c9d1e4801ac7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab776d86-4ea1-401f-98df-c9d1e4801ac7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Values\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 428.776538238172,\n        \"min\": 0.0,\n        \"max\": 1213.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.23577906018136852,\n          1.0,\n          0.4246598219123659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K nearest nodes and weights on important brain regions"
      ],
      "metadata": {
        "id": "EciJ2dNT9sn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(This doesn't work lol)\n",
        "ADHD_Outcome"
      ],
      "metadata": {
        "id": "Al_NlSVz9x8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset graph_fcm before running below cell\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np  # Ensure NumPy is imported\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Assuming 'graph_fcm' DataFrame is already loaded and preprocessed\n",
        "# Remove 'Sex_F' column\n",
        "graph_fcm = graph_fcm.drop('Sex_F', axis=1)\n",
        "\n",
        "# Prepare data for PyTorch Geometric\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels = graph_fcm['ADHD_Outcome'].values\n",
        "\n",
        "# Create an adjacency matrix with actual adjacency correlations\n",
        "adjacency_matrix = np.abs(np.corrcoef(features, rowvar=False))\n",
        "adjacency_matrix[adjacency_matrix < 0.5] = 0  # Apply threshold\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "# K nearest neighbors\n",
        "\n",
        "k = 5\n",
        "top_k_mask = np.zeros_like(adjacency_matrix)  # Fixed initialization\n",
        "for i in range(adjacency_matrix.shape[0]):  # Iterate over rows (brain regions)\n",
        "    top_k_indices = np.argsort(adjacency_matrix[i])[-k:]  # Get top-K most correlated regions\n",
        "    top_k_mask[i, top_k_indices] = adjacency_matrix[i, top_k_indices]  # Keep only top-K\n",
        "\n",
        "adjacency_matrix = top_k_mask  # Update adjacency matrix\n",
        "\n",
        "# Convert to PyTorch tensors and move to device\n",
        "edge_index = np.array(np.where(adjacency_matrix > 0))  # Extract edges\n",
        "edge_weight = adjacency_matrix[edge_index[0], edge_index[1]]  # Extract weights\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(edge_index, dtype=torch.long).to(device),\n",
        "    edge_attr=torch.tensor(edge_weight, dtype=torch.float32).to(device),  # Edge weights\n",
        "    y=torch.tensor(labels, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = data.num_features\n",
        "hidden_channels = 64\n",
        "out_channels = 2  # Two classes: ADHD (1) and no ADHD (0)\n",
        "learning_rate = 0.01\n",
        "epochs = 200\n",
        "\n",
        "# Model, optimizer, and loss function\n",
        "model_adhd = GCN(in_channels, hidden_channels, out_channels).to(device)\n",
        "optimizer = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model\n",
        "model_adhd.train()\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    out = model_adhd(data.x, data.edge_index)\n",
        "    loss = criterion(out, data.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model_adhd.eval()\n",
        "_, pred = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "correct = float(pred.eq(data.y).sum().item())\n",
        "acc = correct / len(data.y)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "54uG2zZD9zZf",
        "outputId": "b2f6b921-edb5-4534-90b8-e5d9b3417efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-678ceb12af92>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_adhd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-678ceb12af92>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'source_to_target'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0medge_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0medge_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optuna optimizing on F1 score instead of accuracy w/kaggle weights (88% train on all, but overfitting af)"
      ],
      "metadata": {
        "id": "NTcbcQUs2XCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tfc9WYi2f2D",
        "outputId": "19a206b0-0f77-47df-848b-1f7694478b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Merge data\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "# Extract feature matrix\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels_adhd = graph_fcm['ADHD_Outcome'].values\n",
        "labels_sex = graph_fcm['Sex_F'].values\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_nodes = features.shape[0]  # Ensure correct shape (number of samples, not features)\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5))) #LITERALLY JUST DIVIDED IN HALF SO ITS NOT FULLY CONNECTED ITS HALF CONNECTED?\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y_adhd=torch.tensor(labels_adhd, dtype=torch.long).to(device),\n",
        "    y_sex=torch.tensor(labels_sex, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    hidden_channels = trial.suggest_categorical('hidden_channels', [1,2,3,4,5,6])\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
        "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
        "\n",
        "    class GCN(torch.nn.Module):\n",
        "        def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "            super().__init__()\n",
        "            self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "            self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        def forward(self, x, edge_index):\n",
        "            x = self.conv1(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=dropout_rate, training=self.training)\n",
        "            x = self.conv2(x, edge_index)\n",
        "            return F.log_softmax(x, dim=1)\n",
        "\n",
        "    # Initialize models\n",
        "    model_adhd = GCN(data.num_features, hidden_channels, 2).to(device)\n",
        "    model_sex = GCN(data.num_features, hidden_channels, 2).to(device)\n",
        "\n",
        "    optimizer_adhd = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    optimizer_sex = torch.optim.Adam(model_sex.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(100):\n",
        "        model_adhd.train()\n",
        "        optimizer_adhd.zero_grad()\n",
        "        out_adhd = model_adhd(data.x, data.edge_index)\n",
        "        loss_adhd = criterion(out_adhd, data.y_adhd)\n",
        "        loss_adhd.backward()\n",
        "        optimizer_adhd.step()\n",
        "\n",
        "        model_sex.train()\n",
        "        optimizer_sex.zero_grad()\n",
        "        out_sex = model_sex(data.x, data.edge_index)\n",
        "        loss_sex = criterion(out_sex, data.y_sex)\n",
        "        loss_sex.backward()\n",
        "        optimizer_sex.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model_adhd.eval()\n",
        "    model_sex.eval()\n",
        "\n",
        "    _, pred_adhd = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "    _, pred_sex = model_sex(data.x, data.edge_index).max(dim=1)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    pred_adhd_np = pred_adhd.cpu().numpy()\n",
        "    true_adhd_np = data.y_adhd.cpu().numpy()\n",
        "\n",
        "    pred_sex_np = pred_sex.cpu().numpy()\n",
        "    true_sex_np = data.y_sex.cpu().numpy()\n",
        "\n",
        "    # Assign weights (2x weight for Female ADHD cases)\n",
        "    sample_weights = np.ones_like(true_adhd_np, dtype=float)\n",
        "    sample_weights[(true_adhd_np == 1) & (true_sex_np == 1)] *= 2  # Female ADHD cases\n",
        "\n",
        "    # Compute weighted F1 scores\n",
        "    f1_adhd = f1_score(true_adhd_np, pred_adhd_np, average=\"binary\", sample_weight=sample_weights)\n",
        "    f1_sex = f1_score(true_sex_np, pred_sex_np, average=\"binary\")\n",
        "\n",
        "    # Compute final score (averaged)\n",
        "    weighted_f1 = (f1_adhd + f1_sex) / 2\n",
        "\n",
        "    return weighted_f1  # Optuna will maximize this\n",
        "\n",
        "# Run the optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best hyperparameters:\", study.best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nibmyow2V1Q",
        "outputId": "256f140a-9ac1-48e4-c5af-948875df61df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-06 18:50:10,969] A new study created in memory with name: no-name-be163ad3-a4d4-4e66-8627-855bfece3bad\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:12,162] Trial 0 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 3, 'learning_rate': 0.002162604271702988, 'dropout_rate': 0.22936458840994428, 'weight_decay': 1.0428320660791374e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:13,323] Trial 1 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 6, 'learning_rate': 0.0003082379789017399, 'dropout_rate': 0.46328661500476104, 'weight_decay': 1.508922709619925e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:14,493] Trial 2 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.0026063464619156857, 'dropout_rate': 0.3639592514330744, 'weight_decay': 3.5745492572169506e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:15,523] Trial 3 finished with value: 0.8016628526041789 and parameters: {'hidden_channels': 5, 'learning_rate': 0.0001317943915805747, 'dropout_rate': 0.3721200887111614, 'weight_decay': 6.80167863679929e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:16,794] Trial 4 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.0023251701023128146, 'dropout_rate': 0.4457250503448178, 'weight_decay': 0.00023467830635570637}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:17,704] Trial 5 finished with value: 0.8478815808209602 and parameters: {'hidden_channels': 2, 'learning_rate': 0.0004386927730707042, 'dropout_rate': 0.48607494544897795, 'weight_decay': 5.374987658957496e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:19,043] Trial 6 finished with value: 0.4711751847437921 and parameters: {'hidden_channels': 2, 'learning_rate': 0.0029888764778722076, 'dropout_rate': 0.5347094944301956, 'weight_decay': 0.00018145106990636898}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:20,439] Trial 7 finished with value: 0.8491204190641176 and parameters: {'hidden_channels': 3, 'learning_rate': 0.0005070548257650725, 'dropout_rate': 0.2920968801142922, 'weight_decay': 3.664091611666036e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:21,853] Trial 8 finished with value: 0.46877710320901994 and parameters: {'hidden_channels': 3, 'learning_rate': 0.009329711154051895, 'dropout_rate': 0.2732001786193521, 'weight_decay': 2.6109882775402467e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:22,706] Trial 9 finished with value: 0.8086250873515024 and parameters: {'hidden_channels': 2, 'learning_rate': 0.0031564058468861516, 'dropout_rate': 0.5804616507487441, 'weight_decay': 2.120219815954646e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:23,726] Trial 10 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 4, 'learning_rate': 0.009112768771047346, 'dropout_rate': 0.20230114901052657, 'weight_decay': 7.368913742105564e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:24,375] Trial 11 finished with value: 0.8412568491186729 and parameters: {'hidden_channels': 6, 'learning_rate': 0.00015955352077599982, 'dropout_rate': 0.4428103614783737, 'weight_decay': 1.7091820952934447e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:25,024] Trial 12 finished with value: 0.8502552790166084 and parameters: {'hidden_channels': 6, 'learning_rate': 0.0010264493586864122, 'dropout_rate': 0.3055553892563713, 'weight_decay': 8.267002204098063e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:25,649] Trial 13 finished with value: 0.8062270216299946 and parameters: {'hidden_channels': 1, 'learning_rate': 0.0003181273990341041, 'dropout_rate': 0.21761758558153554, 'weight_decay': 1.0769857656622313e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:26,290] Trial 14 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 3, 'learning_rate': 0.000977981728932523, 'dropout_rate': 0.4040049520575787, 'weight_decay': 5.003568422937331e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:26,947] Trial 15 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 6, 'learning_rate': 0.001140951701322589, 'dropout_rate': 0.5023783009948283, 'weight_decay': 1.335485342325761e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:27,576] Trial 16 finished with value: 0.42492138364779874 and parameters: {'hidden_channels': 1, 'learning_rate': 0.00019076558919019232, 'dropout_rate': 0.5764846185629231, 'weight_decay': 2.7773926472180343e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:28,217] Trial 17 finished with value: 0.8515664207164384 and parameters: {'hidden_channels': 4, 'learning_rate': 0.0006529795149102544, 'dropout_rate': 0.32637139911133284, 'weight_decay': 0.0005350484163424028}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:28,858] Trial 18 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 3, 'learning_rate': 0.0051468343863542544, 'dropout_rate': 0.2576144567616538, 'weight_decay': 4.143586230383271e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:29,510] Trial 19 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 6, 'learning_rate': 0.0016100217268553046, 'dropout_rate': 0.42684266958545225, 'weight_decay': 1.1332378701715298e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:30,159] Trial 20 finished with value: 0.8522776092086886 and parameters: {'hidden_channels': 6, 'learning_rate': 0.0002150641674235595, 'dropout_rate': 0.35193067418809076, 'weight_decay': 1.4817648219095627e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:30,811] Trial 21 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.004398664415608853, 'dropout_rate': 0.3721380334304577, 'weight_decay': 9.558169779072061e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:31,460] Trial 22 finished with value: 0.4711751847437921 and parameters: {'hidden_channels': 5, 'learning_rate': 0.001815080825236323, 'dropout_rate': 0.48251656877894794, 'weight_decay': 2.9319621215874665e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:32,203] Trial 23 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.0016179463511990881, 'dropout_rate': 0.23175020405073085, 'weight_decay': 1.5602468609953478e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:32,945] Trial 24 finished with value: 0.806960692142694 and parameters: {'hidden_channels': 3, 'learning_rate': 0.0007389401082993002, 'dropout_rate': 0.3368926802822014, 'weight_decay': 0.00011408487796722518}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:33,795] Trial 25 finished with value: 0.4515455304928989 and parameters: {'hidden_channels': 1, 'learning_rate': 0.00010221075731111479, 'dropout_rate': 0.5272572860385875, 'weight_decay': 8.0220702316613e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:34,657] Trial 26 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 4, 'learning_rate': 0.0051591690087968755, 'dropout_rate': 0.40228754282888574, 'weight_decay': 3.507230501223232e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:35,299] Trial 27 finished with value: 0.46655157531290464 and parameters: {'hidden_channels': 3, 'learning_rate': 0.00030718224532709867, 'dropout_rate': 0.46892324936511287, 'weight_decay': 2.1115828010907723e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:35,960] Trial 28 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 6, 'learning_rate': 0.0036354739705902893, 'dropout_rate': 0.26386647888936254, 'weight_decay': 4.7132576244594585e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:36,620] Trial 29 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.006990049822889556, 'dropout_rate': 0.37923298241208514, 'weight_decay': 5.9696797435805816e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:37,268] Trial 30 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.0021394520868494825, 'dropout_rate': 0.5512354014882848, 'weight_decay': 0.0003847070099313579}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:37,937] Trial 31 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.002474888297532508, 'dropout_rate': 0.44428681681470994, 'weight_decay': 0.00022912285479673275}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:38,598] Trial 32 finished with value: 0.4711751847437921 and parameters: {'hidden_channels': 5, 'learning_rate': 0.00131123622340011, 'dropout_rate': 0.4615826967497965, 'weight_decay': 0.0007078870663517317}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:39,246] Trial 33 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.002620023202565269, 'dropout_rate': 0.4244504252665734, 'weight_decay': 0.000274651520856325}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:39,878] Trial 34 finished with value: 0.4711751847437921 and parameters: {'hidden_channels': 2, 'learning_rate': 0.0020859533806636115, 'dropout_rate': 0.5067249237224188, 'weight_decay': 0.00011992047575176667}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:40,524] Trial 35 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.003942207695999019, 'dropout_rate': 0.3874269666021988, 'weight_decay': 0.0009179674558124981}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:41,170] Trial 36 finished with value: 0.8096296296296297 and parameters: {'hidden_channels': 3, 'learning_rate': 0.000704065492403849, 'dropout_rate': 0.30650602791625936, 'weight_decay': 4.7791683073662293e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:41,795] Trial 37 finished with value: 0.8062080851223259 and parameters: {'hidden_channels': 2, 'learning_rate': 0.00044901971644827526, 'dropout_rate': 0.3579488553699146, 'weight_decay': 0.00016001341560920843}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:42,457] Trial 38 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 5, 'learning_rate': 0.006640959292655979, 'dropout_rate': 0.45298468014143134, 'weight_decay': 7.835900989304393e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:43,114] Trial 39 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 6, 'learning_rate': 0.002921303145572965, 'dropout_rate': 0.4925228571983318, 'weight_decay': 2.5275197214224112e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:43,768] Trial 40 finished with value: 0.4711751847437921 and parameters: {'hidden_channels': 4, 'learning_rate': 0.001275651445088622, 'dropout_rate': 0.4183288153739651, 'weight_decay': 1.0033636114254336e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:44,424] Trial 41 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 4, 'learning_rate': 0.008936403879912132, 'dropout_rate': 0.20778148127591792, 'weight_decay': 6.92502237693988e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:45,208] Trial 42 finished with value: 0.8522776092086886 and parameters: {'hidden_channels': 4, 'learning_rate': 0.0009035354498474786, 'dropout_rate': 0.23826584209262908, 'weight_decay': 3.1269463495369087e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:45,997] Trial 43 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 4, 'learning_rate': 0.00032766065085626246, 'dropout_rate': 0.2405707903565301, 'weight_decay': 1.5630149550021617e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:46,919] Trial 44 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 3, 'learning_rate': 0.0054539310713115985, 'dropout_rate': 0.20069433234993242, 'weight_decay': 1.9930700128888483e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:47,545] Trial 45 finished with value: 0.42492138364779874 and parameters: {'hidden_channels': 1, 'learning_rate': 0.0034424282725859633, 'dropout_rate': 0.28021198235594097, 'weight_decay': 6.343324488990696e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:48,199] Trial 46 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 6, 'learning_rate': 0.0005607307043518207, 'dropout_rate': 0.22578122045568397, 'weight_decay': 4.2402605563940685e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:48,827] Trial 47 finished with value: 0.46877710320901994 and parameters: {'hidden_channels': 2, 'learning_rate': 0.009893650292347303, 'dropout_rate': 0.2967927733161473, 'weight_decay': 3.5258838072011955e-06}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:49,464] Trial 48 finished with value: 0.8524808069127237 and parameters: {'hidden_channels': 4, 'learning_rate': 0.007224964859991422, 'dropout_rate': 0.2493971735962732, 'weight_decay': 1.1558785056040112e-05}. Best is trial 0 with value: 0.8524808069127237.\n",
            "<ipython-input-4-0398fa9bd21d>:34: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-4-0398fa9bd21d>:35: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.2, 0.6)\n",
            "<ipython-input-4-0398fa9bd21d>:36: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 18:50:50,124] Trial 49 finished with value: 0.8087921818790871 and parameters: {'hidden_channels': 3, 'learning_rate': 0.0013798925468284093, 'dropout_rate': 0.3252876815753797, 'weight_decay': 1.8747675673236394e-05}. Best is trial 0 with value: 0.8524808069127237.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'hidden_channels': 3, 'learning_rate': 0.002162604271702988, 'dropout_rate': 0.22936458840994428, 'weight_decay': 1.0428320660791374e-05}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "\n",
        "# Extract feature matrix and labels\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels_adhd = graph_fcm['ADHD_Outcome'].values\n",
        "labels_sex = graph_fcm['Sex_F'].values\n",
        "\n",
        "# Define adjacency matrix\n",
        "num_nodes = features.shape[0]\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5)))\n",
        "np.fill_diagonal(adjacency_matrix, 0)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y_adhd=torch.tensor(labels_adhd, dtype=torch.long).to(device),\n",
        "    y_sex=torch.tensor(labels_sex, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Best hyperparameters from Optuna\n",
        "best_params = {\n",
        "    'hidden_channels': 5,  # Example value, update with actual results\n",
        "    'learning_rate': 0.003499557669482012,\n",
        "    'dropout_rate':  0.2208599538827401,\n",
        "    'weight_decay': 0.0006859889083452554\n",
        "}\n",
        "\n",
        "# Define GCN model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=best_params['dropout_rate'], training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Initialize models\n",
        "model_adhd = GCN(data.num_features, best_params['hidden_channels'], 2).to(device)\n",
        "model_sex = GCN(data.num_features, best_params['hidden_channels'], 2).to(device)\n",
        "\n",
        "optimizer_adhd = torch.optim.Adam(model_adhd.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
        "optimizer_sex = torch.optim.Adam(model_sex.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train models\n",
        "for epoch in range(100):\n",
        "    model_adhd.train()\n",
        "    optimizer_adhd.zero_grad()\n",
        "    out_adhd = model_adhd(data.x, data.edge_index)\n",
        "    loss_adhd = criterion(out_adhd, data.y_adhd)\n",
        "    loss_adhd.backward()\n",
        "    optimizer_adhd.step()\n",
        "\n",
        "    model_sex.train()\n",
        "    optimizer_sex.zero_grad()\n",
        "    out_sex = model_sex(data.x, data.edge_index)\n",
        "    loss_sex = criterion(out_sex, data.y_sex)\n",
        "    loss_sex.backward()\n",
        "    optimizer_sex.step()\n",
        "\n",
        "# Make predictions\n",
        "model_adhd.eval()\n",
        "model_sex.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    _, pred_adhd = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "    _, pred_sex = model_sex(data.x, data.edge_index).max(dim=1)\n",
        "\n",
        "    accuracy_adhd = (pred_adhd == data.y_adhd).float().mean().item()\n",
        "    accuracy_sex = (pred_sex == data.y_sex).float().mean().item()\n",
        "    f1_adhd = f1_score(data.y_adhd.cpu().numpy(), pred_adhd.cpu().numpy(), average=\"weighted\")\n",
        "    f1_sex = f1_score(data.y_sex.cpu().numpy(), pred_sex.cpu().numpy(), average=\"weighted\")\n",
        "\n",
        "print(f\"Training Accuracy - ADHD Outcome: {accuracy_adhd:.4f}\")\n",
        "print(f\"Training Accuracy - Sex Classification: {accuracy_sex:.4f}\")\n",
        "print(f\"Training F1 Score - ADHD Outcome: {f1_adhd:.4f}\")\n",
        "print(f\"Training F1 Score - Sex Classification: {f1_sex:.4f}\")\n",
        "print(\"Cell complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY30Um907pYB",
        "outputId": "0e2f9924-e4d1-47fa-aff2-cb5bd303b322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy - ADHD Outcome: 0.8813\n",
            "Training Accuracy - Sex Classification: 0.8706\n",
            "Training F1 Score - ADHD Outcome: 0.8722\n",
            "Training F1 Score - Sex Classification: 0.8613\n",
            "Cell complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##optuna with train test split? (didn't help much)"
      ],
      "metadata": {
        "id": "NcWHcVw6vJi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhAPtYBpYG7H",
        "outputId": "897c7a1d-8771-4fa0-ee32-68a905f80166"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.15.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge data\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "# Extract feature matrix\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels_adhd = graph_fcm['ADHD_Outcome'].values\n",
        "labels_sex = graph_fcm['Sex_F'].values\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train-Validation Split\n",
        "train_idx, val_idx = train_test_split(np.arange(len(features)), test_size=0.2, random_state=42, stratify=labels_adhd)\n",
        "train_mask = torch.zeros(len(features), dtype=torch.bool)\n",
        "train_mask[train_idx] = True\n",
        "val_mask = ~train_mask\n",
        "\n",
        "# Create adjacency matrix\n",
        "num_nodes = features.shape[0]\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5)))\n",
        "np.fill_diagonal(adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y_adhd=torch.tensor(labels_adhd, dtype=torch.long).to(device),\n",
        "    y_sex=torch.tensor(labels_sex, dtype=torch.long).to(device),\n",
        "    train_mask=train_mask.to(device),\n",
        "    val_mask=val_mask.to(device)\n",
        ")\n",
        "\n",
        "# Define the objective function\n",
        "def objective(trial):\n",
        "    hidden_channels = trial.suggest_int('hidden_channels', 65, 95)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
        "    dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
        "    dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
        "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
        "    patience = 10  # Early stopping patience\n",
        "\n",
        "    class GCN(torch.nn.Module):\n",
        "        def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "            super().__init__()\n",
        "            self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "            self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        def forward(self, x, edge_index):\n",
        "            x = self.conv1(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=dropout_rate1, training=self.training)\n",
        "            x = self.conv2(x, edge_index)\n",
        "            x = F.dropout(x, p=dropout_rate2, training=self.training)\n",
        "            return F.log_softmax(x, dim=1)\n",
        "\n",
        "    # Initialize models\n",
        "    model_adhd = GCN(data.num_features, hidden_channels, 2).to(device)\n",
        "    model_sex = GCN(data.num_features, hidden_channels, 2).to(device)\n",
        "\n",
        "    optimizer_adhd = torch.optim.Adam(model_adhd.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    optimizer_sex = torch.optim.Adam(model_sex.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    no_improve_count = 0\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    for epoch in range(100):\n",
        "        model_adhd.train()\n",
        "        optimizer_adhd.zero_grad()\n",
        "        out_adhd = model_adhd(data.x, data.edge_index)\n",
        "        loss_adhd = criterion(out_adhd[data.train_mask], data.y_adhd[data.train_mask])\n",
        "        loss_adhd.backward()\n",
        "        optimizer_adhd.step()\n",
        "\n",
        "        model_sex.train()\n",
        "        optimizer_sex.zero_grad()\n",
        "        out_sex = model_sex(data.x, data.edge_index)\n",
        "        loss_sex = criterion(out_sex[data.train_mask], data.y_sex[data.train_mask])\n",
        "        loss_sex.backward()\n",
        "        optimizer_sex.step()\n",
        "\n",
        "        # Validation loss\n",
        "        model_adhd.eval()\n",
        "        model_sex.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss_adhd = criterion(out_adhd[data.val_mask], data.y_adhd[data.val_mask]).item()\n",
        "            val_loss_sex = criterion(out_sex[data.val_mask], data.y_sex[data.val_mask]).item()\n",
        "            val_loss = (val_loss_adhd + val_loss_sex) / 2\n",
        "\n",
        "        # Early stopping check\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            no_improve_count = 0\n",
        "        else:\n",
        "            no_improve_count += 1\n",
        "            if no_improve_count >= patience:\n",
        "                break  # Stop training early if no improvement\n",
        "\n",
        "    # Evaluation on validation set\n",
        "    model_adhd.eval()\n",
        "    model_sex.eval()\n",
        "\n",
        "    _, pred_adhd = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "    _, pred_sex = model_sex(data.x, data.edge_index).max(dim=1)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    pred_adhd_np = pred_adhd.cpu().numpy()[val_mask.cpu().numpy()]\n",
        "    true_adhd_np = data.y_adhd.cpu().numpy()[val_mask.cpu().numpy()]\n",
        "\n",
        "    pred_sex_np = pred_sex.cpu().numpy()[val_mask.cpu().numpy()]\n",
        "    true_sex_np = data.y_sex.cpu().numpy()[val_mask.cpu().numpy()]\n",
        "\n",
        "    # Assign weights (2x weight for Female ADHD cases)\n",
        "    sample_weights = np.ones_like(true_adhd_np, dtype=float)\n",
        "    sample_weights[(true_adhd_np == 1) & (true_sex_np == 1)] *= 2  # Female ADHD cases\n",
        "\n",
        "    # Compute weighted F1 scores\n",
        "    f1_adhd = f1_score(true_adhd_np, pred_adhd_np, average=\"binary\", sample_weight=sample_weights)\n",
        "    f1_sex = f1_score(true_sex_np, pred_sex_np, average=\"binary\")\n",
        "\n",
        "    # Compute final score (averaged)\n",
        "    weighted_f1 = (f1_adhd + f1_sex) / 2\n",
        "\n",
        "    return weighted_f1  # Optuna will maximize this\n",
        "\n",
        "# Run the optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd1VQibFzQrC",
        "outputId": "16b4e72e-8108-43e1-9fc5-5721a1999529"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-03-06 21:33:25,010] A new study created in memory with name: no-name-d6d91e16-8cd1-402d-9dac-61963df02c5a\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:25,625] Trial 0 finished with value: 0.4231536926147705 and parameters: {'hidden_channels': 87, 'learning_rate': 0.00016671119733972187, 'dropout_rate1': 0.7231380416461397, 'dropout_rate2': 0.27584280308017445, 'weight_decay': 0.00011817737430052032}. Best is trial 0 with value: 0.4231536926147705.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:26,246] Trial 1 finished with value: 0.5182798921186694 and parameters: {'hidden_channels': 83, 'learning_rate': 0.0006411271899080778, 'dropout_rate1': 0.23229586106253403, 'dropout_rate2': 0.3741493238446596, 'weight_decay': 6.929629749624538e-06}. Best is trial 1 with value: 0.5182798921186694.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:27,025] Trial 2 finished with value: 0.4231536926147705 and parameters: {'hidden_channels': 87, 'learning_rate': 0.00015253390930609342, 'dropout_rate1': 0.7592160634822938, 'dropout_rate2': 0.5121544946761158, 'weight_decay': 0.00018938925389227473}. Best is trial 1 with value: 0.5182798921186694.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:28,022] Trial 3 finished with value: 0.6007131976180584 and parameters: {'hidden_channels': 95, 'learning_rate': 0.006493244317683886, 'dropout_rate1': 0.38938959108969085, 'dropout_rate2': 0.4540909590774793, 'weight_decay': 1.452578055457299e-06}. Best is trial 3 with value: 0.6007131976180584.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:29,017] Trial 4 finished with value: 0.5660108354719133 and parameters: {'hidden_channels': 88, 'learning_rate': 0.009778450649804026, 'dropout_rate1': 0.4530717870217362, 'dropout_rate2': 0.426409897306766, 'weight_decay': 6.997997927155645e-05}. Best is trial 3 with value: 0.6007131976180584.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:30,160] Trial 5 finished with value: 0.5458183273309324 and parameters: {'hidden_channels': 81, 'learning_rate': 0.0020133200387191445, 'dropout_rate1': 0.6143055768796851, 'dropout_rate2': 0.6043087499559817, 'weight_decay': 8.173528386604691e-05}. Best is trial 3 with value: 0.6007131976180584.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:31,151] Trial 6 finished with value: 0.4713464636991078 and parameters: {'hidden_channels': 75, 'learning_rate': 0.00024060116228887777, 'dropout_rate1': 0.4026314832995528, 'dropout_rate2': 0.7024269795265017, 'weight_decay': 4.5974723172370505e-06}. Best is trial 3 with value: 0.6007131976180584.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:33,333] Trial 7 finished with value: 0.4231536926147705 and parameters: {'hidden_channels': 70, 'learning_rate': 0.00011028647802502091, 'dropout_rate1': 0.5821907312028758, 'dropout_rate2': 0.3896921750819212, 'weight_decay': 3.829725595636172e-06}. Best is trial 3 with value: 0.6007131976180584.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:35,024] Trial 8 finished with value: 0.6530612244897959 and parameters: {'hidden_channels': 77, 'learning_rate': 0.009475981369333784, 'dropout_rate1': 0.5722744990820475, 'dropout_rate2': 0.44886519988585993, 'weight_decay': 0.00012845587185336593}. Best is trial 8 with value: 0.6530612244897959.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:35,734] Trial 9 finished with value: 0.4231536926147705 and parameters: {'hidden_channels': 76, 'learning_rate': 0.00012294112068220994, 'dropout_rate1': 0.4968167658822234, 'dropout_rate2': 0.5768408540752659, 'weight_decay': 0.00035318043364242853}. Best is trial 8 with value: 0.6530612244897959.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:36,747] Trial 10 finished with value: 0.520431493182574 and parameters: {'hidden_channels': 66, 'learning_rate': 0.003111374649660945, 'dropout_rate1': 0.257345879349568, 'dropout_rate2': 0.21072881203234767, 'weight_decay': 2.0814965302915744e-05}. Best is trial 8 with value: 0.6530612244897959.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:38,180] Trial 11 finished with value: 0.6067105329248079 and parameters: {'hidden_channels': 93, 'learning_rate': 0.007819911868927656, 'dropout_rate1': 0.38538760637480324, 'dropout_rate2': 0.4692320498666921, 'weight_decay': 1.0039591803477225e-06}. Best is trial 8 with value: 0.6530612244897959.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:39,986] Trial 12 finished with value: 0.5130413330642087 and parameters: {'hidden_channels': 92, 'learning_rate': 0.00443409857104058, 'dropout_rate1': 0.3222837189267054, 'dropout_rate2': 0.7484193683874302, 'weight_decay': 0.0006601093708433082}. Best is trial 8 with value: 0.6530612244897959.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:40,661] Trial 13 finished with value: 0.44847014831097304 and parameters: {'hidden_channels': 76, 'learning_rate': 0.0013337861986913672, 'dropout_rate1': 0.5958702714281721, 'dropout_rate2': 0.32161874054976636, 'weight_decay': 3.106645579047175e-05}. Best is trial 8 with value: 0.6530612244897959.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:42,213] Trial 14 finished with value: 0.6007237860727144 and parameters: {'hidden_channels': 72, 'learning_rate': 0.009264002175539974, 'dropout_rate1': 0.6699876991540705, 'dropout_rate2': 0.5353659478524673, 'weight_decay': 1.164813520211909e-06}. Best is trial 8 with value: 0.6530612244897959.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:43,011] Trial 15 finished with value: 0.5273203592814372 and parameters: {'hidden_channels': 82, 'learning_rate': 0.0005929325605121726, 'dropout_rate1': 0.544724569488294, 'dropout_rate2': 0.6442916879195981, 'weight_decay': 1.0150170114601697e-05}. Best is trial 8 with value: 0.6530612244897959.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:44,439] Trial 16 finished with value: 0.6636170614849317 and parameters: {'hidden_channels': 78, 'learning_rate': 0.004116140222105535, 'dropout_rate1': 0.3548644082699346, 'dropout_rate2': 0.4868345888838423, 'weight_decay': 1.7247415325725915e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:46,538] Trial 17 finished with value: 0.4860317167619399 and parameters: {'hidden_channels': 78, 'learning_rate': 0.0036552102640478993, 'dropout_rate1': 0.3139746294006078, 'dropout_rate2': 0.34146622582427, 'weight_decay': 1.665784950435824e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:47,478] Trial 18 finished with value: 0.46317252816935756 and parameters: {'hidden_channels': 71, 'learning_rate': 0.002246660132961721, 'dropout_rate1': 0.4903626258367337, 'dropout_rate2': 0.7995344269720523, 'weight_decay': 0.0002440940238658067}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:48,433] Trial 19 finished with value: 0.424 and parameters: {'hidden_channels': 66, 'learning_rate': 0.0061826913632143906, 'dropout_rate1': 0.6480217343819904, 'dropout_rate2': 0.52440998873979, 'weight_decay': 5.122565632318705e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:49,568] Trial 20 finished with value: 0.5466867469879518 and parameters: {'hidden_channels': 85, 'learning_rate': 0.001181059478940211, 'dropout_rate1': 0.315301737944525, 'dropout_rate2': 0.6289922810192475, 'weight_decay': 0.0007755108109481764}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:51,058] Trial 21 finished with value: 0.5888463641334063 and parameters: {'hidden_channels': 79, 'learning_rate': 0.006305787568972748, 'dropout_rate1': 0.40506831962267464, 'dropout_rate2': 0.46239461152017475, 'weight_decay': 2.4471273136970807e-06}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:52,643] Trial 22 finished with value: 0.6169152542372881 and parameters: {'hidden_channels': 90, 'learning_rate': 0.005450493840689606, 'dropout_rate1': 0.44261935281072773, 'dropout_rate2': 0.4704473039516829, 'weight_decay': 3.650318515351483e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:53,849] Trial 23 finished with value: 0.4254241852949098 and parameters: {'hidden_channels': 73, 'learning_rate': 0.004137256098207424, 'dropout_rate1': 0.536795115331065, 'dropout_rate2': 0.4100762666183268, 'weight_decay': 3.360797167683849e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:54,755] Trial 24 finished with value: 0.5558067538392603 and parameters: {'hidden_channels': 79, 'learning_rate': 0.0026956037663005104, 'dropout_rate1': 0.429575382767142, 'dropout_rate2': 0.5574244180529314, 'weight_decay': 1.2889983122350262e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:55,632] Trial 25 finished with value: 0.49218181818181816 and parameters: {'hidden_channels': 90, 'learning_rate': 0.005089004119697388, 'dropout_rate1': 0.34734572936284663, 'dropout_rate2': 0.4668415372088613, 'weight_decay': 3.432409529966203e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:56,484] Trial 26 finished with value: 0.5237216884008237 and parameters: {'hidden_channels': 83, 'learning_rate': 0.0016664891775419832, 'dropout_rate1': 0.46274514920497606, 'dropout_rate2': 0.4984376604721553, 'weight_decay': 0.00012976178226081382}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:57,925] Trial 27 finished with value: 0.4812932274984914 and parameters: {'hidden_channels': 69, 'learning_rate': 0.0005586897596141959, 'dropout_rate1': 0.5456951177257595, 'dropout_rate2': 0.35936204965900653, 'weight_decay': 4.572829348180543e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:33:59,984] Trial 28 finished with value: 0.4719341804196485 and parameters: {'hidden_channels': 74, 'learning_rate': 0.005064978487765699, 'dropout_rate1': 0.2873386979880339, 'dropout_rate2': 0.2881059080721129, 'weight_decay': 0.00044442698551211684}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:01,171] Trial 29 finished with value: 0.43581192046287176 and parameters: {'hidden_channels': 85, 'learning_rate': 0.0003482496072430299, 'dropout_rate1': 0.7023313529442063, 'dropout_rate2': 0.22406162176623007, 'weight_decay': 0.00011760198439629072}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:02,259] Trial 30 finished with value: 0.5227714983645924 and parameters: {'hidden_channels': 77, 'learning_rate': 0.0008304850179685763, 'dropout_rate1': 0.2083266036329705, 'dropout_rate2': 0.4237041492390983, 'weight_decay': 2.1363321040483282e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:03,134] Trial 31 finished with value: 0.43108196169935464 and parameters: {'hidden_channels': 95, 'learning_rate': 0.007582952928371734, 'dropout_rate1': 0.3681859943368503, 'dropout_rate2': 0.4472307948730952, 'weight_decay': 7.759448874962863e-06}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:04,138] Trial 32 finished with value: 0.4452020202020202 and parameters: {'hidden_channels': 92, 'learning_rate': 0.009931931497364202, 'dropout_rate1': 0.4779507446364796, 'dropout_rate2': 0.489434625021921, 'weight_decay': 2.855973063196338e-06}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:05,145] Trial 33 finished with value: 0.6337209302325582 and parameters: {'hidden_channels': 92, 'learning_rate': 0.007164003030295349, 'dropout_rate1': 0.4272736035572128, 'dropout_rate2': 0.38308268961386227, 'weight_decay': 0.00012394498746711496}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:06,185] Trial 34 finished with value: 0.5396787148594377 and parameters: {'hidden_channels': 89, 'learning_rate': 0.0058095278515047696, 'dropout_rate1': 0.42899383184651607, 'dropout_rate2': 0.38289421178792443, 'weight_decay': 0.00014985497882139968}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:07,083] Trial 35 finished with value: 0.502699147160225 and parameters: {'hidden_channels': 86, 'learning_rate': 0.003324163884947382, 'dropout_rate1': 0.5180122513688868, 'dropout_rate2': 0.29565671668113014, 'weight_decay': 8.465964424656444e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:07,944] Trial 36 finished with value: 0.553921568627451 and parameters: {'hidden_channels': 90, 'learning_rate': 0.0026100020691019977, 'dropout_rate1': 0.4339695808514096, 'dropout_rate2': 0.41186219985850575, 'weight_decay': 0.0001938394276908822}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:09,543] Trial 37 finished with value: 0.6026408721019499 and parameters: {'hidden_channels': 83, 'learning_rate': 0.007382601984474088, 'dropout_rate1': 0.7989020061563143, 'dropout_rate2': 0.2483339908512118, 'weight_decay': 6.112597349491819e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:10,552] Trial 38 finished with value: 0.6148203592814372 and parameters: {'hidden_channels': 80, 'learning_rate': 0.004472013724433764, 'dropout_rate1': 0.37027699983849693, 'dropout_rate2': 0.554563897186212, 'weight_decay': 7.966012594680432e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:12,268] Trial 39 finished with value: 0.646930846930847 and parameters: {'hidden_channels': 93, 'learning_rate': 0.008121818217994162, 'dropout_rate1': 0.5799141448015833, 'dropout_rate2': 0.3308698288299658, 'weight_decay': 0.0002663999002768565}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:12,977] Trial 40 finished with value: 0.4171779141104294 and parameters: {'hidden_channels': 93, 'learning_rate': 0.009909443321050173, 'dropout_rate1': 0.6328110103236355, 'dropout_rate2': 0.32389007865067543, 'weight_decay': 0.0002411900053238052}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:13,929] Trial 41 finished with value: 0.6379187932859114 and parameters: {'hidden_channels': 95, 'learning_rate': 0.00759575531614698, 'dropout_rate1': 0.5786473389402034, 'dropout_rate2': 0.36335954043387625, 'weight_decay': 0.00034097014742939666}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:14,389] Trial 42 finished with value: 0.4701927710843373 and parameters: {'hidden_channels': 94, 'learning_rate': 0.007348638350720912, 'dropout_rate1': 0.5875408852104255, 'dropout_rate2': 0.3799774166268989, 'weight_decay': 0.00042492328969311255}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:15,210] Trial 43 finished with value: 0.5689230147504546 and parameters: {'hidden_channels': 95, 'learning_rate': 0.008469638262434775, 'dropout_rate1': 0.5658711150773639, 'dropout_rate2': 0.35045723048446076, 'weight_decay': 0.00031996199415249303}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:15,927] Trial 44 finished with value: 0.48725490196078436 and parameters: {'hidden_channels': 92, 'learning_rate': 0.006502230497491235, 'dropout_rate1': 0.6184002032387031, 'dropout_rate2': 0.434424984906066, 'weight_decay': 0.0005651143554005604}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:16,437] Trial 45 finished with value: 0.5348711751758664 and parameters: {'hidden_channels': 91, 'learning_rate': 0.004141431539987233, 'dropout_rate1': 0.6767589280611352, 'dropout_rate2': 0.31057421420031694, 'weight_decay': 9.896543965752489e-05}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:17,105] Trial 46 finished with value: 0.41649484536082476 and parameters: {'hidden_channels': 75, 'learning_rate': 0.008394008665162147, 'dropout_rate1': 0.5187045630812628, 'dropout_rate2': 0.25898596135383467, 'weight_decay': 0.0009698198651353614}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:17,642] Trial 47 finished with value: 0.6436261335596524 and parameters: {'hidden_channels': 87, 'learning_rate': 0.006856300966195721, 'dropout_rate1': 0.7276622991934265, 'dropout_rate2': 0.40051512197976913, 'weight_decay': 0.0001915856262692495}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:18,033] Trial 48 finished with value: 0.4592982709280235 and parameters: {'hidden_channels': 88, 'learning_rate': 0.0036884184819906875, 'dropout_rate1': 0.7378447656210775, 'dropout_rate2': 0.3980368134361878, 'weight_decay': 0.0003012642595996056}. Best is trial 16 with value: 0.6636170614849317.\n",
            "<ipython-input-21-6139f5ba9119>:44: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
            "<ipython-input-21-6139f5ba9119>:45: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate1 = trial.suggest_uniform('dropout_rate1', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  dropout_rate2 = trial.suggest_uniform('dropout_rate2', 0.2, 0.8)\n",
            "<ipython-input-21-6139f5ba9119>:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
            "[I 2025-03-06 21:34:18,662] Trial 49 finished with value: 0.5462465514737912 and parameters: {'hidden_channels': 87, 'learning_rate': 0.0019006434411049941, 'dropout_rate1': 0.7931319453897725, 'dropout_rate2': 0.3561273920006303, 'weight_decay': 0.00020314535983835503}. Best is trial 16 with value: 0.6636170614849317.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'hidden_channels': 78, 'learning_rate': 0.004116140222105535, 'dropout_rate1': 0.3548644082699346, 'dropout_rate2': 0.4868345888838423, 'weight_decay': 1.7247415325725915e-05}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Merge data\n",
        "graph_fcm = fcm.merge(fcm_solutions, on=\"participant_id\")\n",
        "\n",
        "# Extract feature matrix and labels\n",
        "connectivity_columns = [col for col in graph_fcm.columns if col not in ['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
        "features = graph_fcm[connectivity_columns].values\n",
        "labels_adhd = graph_fcm['ADHD_Outcome'].values\n",
        "labels_sex = graph_fcm['Sex_F'].values\n",
        "\n",
        "# Define adjacency matrix\n",
        "num_nodes = features.shape[0]\n",
        "adjacency_matrix = np.ones(((int)(num_nodes/2.5), (int)(num_nodes/2.5)))\n",
        "np.fill_diagonal(adjacency_matrix, 0)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "data = Data(\n",
        "    x=torch.tensor(features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(adjacency_matrix)), dtype=torch.long).to(device),\n",
        "    y_adhd=torch.tensor(labels_adhd, dtype=torch.long).to(device),\n",
        "    y_sex=torch.tensor(labels_sex, dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Best hyperparameters from Optuna\n",
        "best_params = {\n",
        "    'hidden_channels': 88,  # Example, update with actual results\n",
        "    'learning_rate': 0.006088453952000685,\n",
        "    'dropout_rate1': 0.21967409916790684,\n",
        "    'dropout_rate2': 0.21038454419996405,\n",
        "    'weight_decay': 4.436906482160754e-05\n",
        "}\n",
        "\n",
        "# Define GCN model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=best_params['dropout_rate1'], training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.dropout(x, p=best_params['dropout_rate2'], training=self.training)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Initialize models\n",
        "model_adhd = GCN(data.num_features, best_params['hidden_channels'], 2).to(device)\n",
        "model_sex = GCN(data.num_features, best_params['hidden_channels'], 2).to(device)\n",
        "\n",
        "optimizer_adhd = torch.optim.Adam(model_adhd.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
        "optimizer_sex = torch.optim.Adam(model_sex.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop with early stopping\n",
        "patience = 10\n",
        "best_val_loss = float('inf')\n",
        "no_improve_count = 0\n",
        "\n",
        "for epoch in range(100):\n",
        "    model_adhd.train()\n",
        "    optimizer_adhd.zero_grad()\n",
        "    out_adhd = model_adhd(data.x, data.edge_index)\n",
        "    loss_adhd = criterion(out_adhd, data.y_adhd)\n",
        "    loss_adhd.backward()\n",
        "    optimizer_adhd.step()\n",
        "\n",
        "    model_sex.train()\n",
        "    optimizer_sex.zero_grad()\n",
        "    out_sex = model_sex(data.x, data.edge_index)\n",
        "    loss_sex = criterion(out_sex, data.y_sex)\n",
        "    loss_sex.backward()\n",
        "    optimizer_sex.step()\n",
        "\n",
        "    # Validation loss\n",
        "    model_adhd.eval()\n",
        "    model_sex.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss_adhd = criterion(out_adhd, data.y_adhd).item()\n",
        "        val_loss_sex = criterion(out_sex, data.y_sex).item()\n",
        "        val_loss = (val_loss_adhd + val_loss_sex) / 2\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        no_improve_count = 0\n",
        "    else:\n",
        "        no_improve_count += 1\n",
        "        if no_improve_count >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "# Make predictions\n",
        "model_adhd.eval()\n",
        "model_sex.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    _, pred_adhd = model_adhd(data.x, data.edge_index).max(dim=1)\n",
        "    _, pred_sex = model_sex(data.x, data.edge_index).max(dim=1)\n",
        "\n",
        "    accuracy_adhd = (pred_adhd == data.y_adhd).float().mean().item()\n",
        "    accuracy_sex = (pred_sex == data.y_sex).float().mean().item()\n",
        "    f1_adhd = f1_score(data.y_adhd.cpu().numpy(), pred_adhd.cpu().numpy(), average=\"weighted\")\n",
        "    f1_sex = f1_score(data.y_sex.cpu().numpy(), pred_sex.cpu().numpy(), average=\"weighted\")\n",
        "\n",
        "print(f\"Training Accuracy - ADHD Outcome: {accuracy_adhd:.4f}\")\n",
        "print(f\"Training Accuracy - Sex Classification: {accuracy_sex:.4f}\")\n",
        "print(f\"Training F1 Score - ADHD Outcome: {f1_adhd:.4f}\")\n",
        "print(f\"Training F1 Score - Sex Classification: {f1_sex:.4f}\")\n",
        "print(\"Model training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tohvkMWy3aty",
        "outputId": "06c9eb83-ca5e-4bc2-d8ed-e465738bfb74"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy - ADHD Outcome: 0.8813\n",
            "Training Accuracy - Sex Classification: 0.8706\n",
            "Training F1 Score - ADHD Outcome: 0.8722\n",
            "Training F1 Score - Sex Classification: 0.8613\n",
            "Model training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Combine FCM and quant (WIP)"
      ],
      "metadata": {
        "id": "RBxsJl4lQhfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iSyqYNoxQjoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kaggle Submission\n",
        "Based on the Google Collab running\n",
        "\n",
        "Both are predicting only not female and ADHD, I think this may be due to the imbalance in the dataset"
      ],
      "metadata": {
        "id": "BmIZqxvTbhZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_fcm = pd.read_csv('TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')"
      ],
      "metadata": {
        "id": "Yzs4Cu5BZ5q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_fcm.columns.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp64aa60aLYY",
        "outputId": "7b20c76f-a5d1-4f91-b2cd-674f13efbf21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19901,)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_fcm.isna().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8_LiqfeaNQX",
        "outputId": "099c3585-1139-4bfa-945d-200e989da104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_fcm.columns.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zer28wyfq7qP",
        "outputId": "3092ae8e-6574-4c6e-b50d-faa46e965ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19903,)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predicting both at once"
      ],
      "metadata": {
        "id": "Ym_B5zzL1Zbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adhd_model = model_adhd\n",
        "sex_f_model = model_sex"
      ],
      "metadata": {
        "id": "UIcuYjrrm-w0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TESTING BOTH MODELS ---\n",
        "\n",
        "test_fcm = pd.read_csv('TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
        "test_features = test_fcm.drop(columns=['participant_id']).values\n",
        "\n",
        "# Create adjacency matrix for test data\n",
        "num_test_nodes = test_features.shape[0]\n",
        "test_adjacency_matrix = np.ones(((int)(num_test_nodes/2.5), (int)(num_test_nodes/2.5))) #UPDATE AS NECESSARY\n",
        "np.fill_diagonal(test_adjacency_matrix, 0)\n",
        "\n",
        "# Create test data object\n",
        "test_data = Data(\n",
        "    x=torch.tensor(test_features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(test_adjacency_matrix)), dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Generate predictions\n",
        "adhd_model.eval()\n",
        "sex_f_model.eval()\n",
        "with torch.no_grad():\n",
        "    test_out_adhd = adhd_model(test_data.x, test_data.edge_index)\n",
        "    test_out_sex = sex_f_model(test_data.x, test_data.edge_index)\n",
        "\n",
        "    test_predictions_adhd = test_out_adhd.argmax(dim=1).cpu().numpy()\n",
        "    test_predictions_sex = test_out_sex.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "# Convert predictions to DataFrame\n",
        "test_results = pd.DataFrame({\n",
        "    'participant_id': test_fcm['participant_id'],\n",
        "    'ADHD_Outcome': test_predictions_adhd,\n",
        "    'Sex_F': test_predictions_sex\n",
        "})\n",
        "\n",
        "# Save results\n",
        "test_results.to_csv(\"predictions.csv\", index=False)\n",
        "print(\"Predictions saved to predictions.csv\")\n",
        "\n",
        "test_results.describe()\n",
        "\n",
        "# Count the occurrences of 0's and 1's in ADHD_Outcome\n",
        "adhd_counts = test_results['ADHD_Outcome'].value_counts()\n",
        "print(\"ADHD_Outcome counts:\")\n",
        "print(adhd_counts)\n",
        "\n",
        "# Count the occurrences of 0's and 1's in Sex_F\n",
        "sex_f_counts = test_results['Sex_F'].value_counts()\n",
        "print(\"\\nSex_F counts:\")\n",
        "print(sex_f_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQfDrorW1Y_j",
        "outputId": "47438dcf-c60a-49bc-c040-e84398341e94"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to predictions.csv\n",
            "ADHD_Outcome counts:\n",
            "ADHD_Outcome\n",
            "1    299\n",
            "0      5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sex_F counts:\n",
            "Sex_F\n",
            "1    295\n",
            "0      9\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting ADHD_Outcome\n",
        "\n",
        "(julia) uhh i messed this up somehow so i did it again below\n"
      ],
      "metadata": {
        "id": "WLL0wSH5cJJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_features = test_fcm.drop(columns=['participant_id']).values\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout_rate):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create adjacency matrix (adjust as needed)\n",
        "num_test_nodes = test_features.shape[0]\n",
        "test_adjacency_matrix = np.ones(((int)(num_test_nodes/3), (int)(num_test_nodes/3)))\n",
        "np.fill_diagonal(test_adjacency_matrix, 0)\n",
        "\n",
        "# Create test data object\n",
        "test_data = Data(\n",
        "    x=torch.tensor(test_features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(test_adjacency_matrix)), dtype=torch.long).to(device)\n",
        ")\n",
        "\n",
        "# Load trained model\n",
        "hidden_channels = 32\n",
        "dropout_rate = 0.394\n",
        "model = GCN(test_data.num_features, hidden_channels, 2, dropout_rate).to(device)\n",
        "model.eval()\n",
        "\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "    test_out = model(test_data.x, test_data.edge_index)\n",
        "    test_predictions = test_out.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "# Convert predictions to DataFrame\n",
        "test_results = pd.DataFrame({\n",
        "    'participant_id': test_fcm['participant_id'],\n",
        "    'ADHD_Outcome': test_predictions\n",
        "})\n",
        "\n",
        "# Save results\n",
        "test_results.to_csv(\"ADHD_Predictions.csv\", index=False)\n",
        "print(\"Predictions saved to ADHD_Predictions.csv\")\n",
        "\n",
        "test_results.describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "O0si1aI4s_5k",
        "outputId": "d24206b7-a04d-42f0-9d20-872e750f91e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to ADHD_Predictions.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADHD_Outcome\n",
              "count    304.000000\n",
              "mean       0.710526\n",
              "std        0.454266\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        1.000000\n",
              "75%        1.000000\n",
              "max        1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10b46ef1-8510-40b9-90fd-ee7a2e30fcfe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADHD_Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>304.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.710526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.454266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10b46ef1-8510-40b9-90fd-ee7a2e30fcfe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-10b46ef1-8510-40b9-90fd-ee7a2e30fcfe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-10b46ef1-8510-40b9-90fd-ee7a2e30fcfe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6002e94a-b048-450d-bbcd-9ee59bc722e0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6002e94a-b048-450d-bbcd-9ee59bc722e0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6002e94a-b048-450d-bbcd-9ee59bc722e0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"test_results\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"ADHD_Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 107.27069817755209,\n        \"min\": 0.0,\n        \"max\": 304.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7105263157894737,\n          1.0,\n          0.45426586692491866\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "old printing to csv cell (i broke it mb)"
      ],
      "metadata": {
        "id": "aGbdAvR0tYuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### GET TEST SET IN PROPER FORM LIKE WE DID WITH TRAINING #######\n",
        "# Prepare test data (ensure it follows the same preprocessing as training data)\n",
        "connectivity_columns = [col for col in test_fcm.columns if col not in ['participant_id', 'ADHD_Outcome', 'Sex_F']]\n",
        "test_features = test_fcm[connectivity_columns].values\n",
        "num_test_nodes = test_features.shape[0]\n",
        "\n",
        "# Create an adjacency matrix for test data (modify as needed)\n",
        "test_adjacency_matrix = np.ones(((int)(num_test_nodes/2.5), (int)(num_test_nodes/2.5)))\n",
        "np.fill_diagonal(test_adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert test data to PyTorch Geometric format\n",
        "test_data = Data(\n",
        "    x=torch.tensor(test_features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(test_adjacency_matrix)), dtype=torch.long).to(device),\n",
        ")\n",
        "\n",
        "######## EVAL #########\n",
        "# put model in eval mode\n",
        "model.eval();\n",
        "\n",
        "# get predictions\n",
        "_, pred = model(test_data.x, test_data.edge_index).max(dim=1)\n",
        "\n",
        "# output\n",
        "output_adhd_df = pd.DataFrame({\n",
        "    'participant_id' : test_fcm['participant_id'].values,\n",
        "    'ADHD_Outcome' : pred.cpu().numpy() #make pred and convert to numpy\n",
        "})\n",
        "\n",
        "print(output_adhd_df)\n",
        "no_adhd_num = output_adhd_df[output_adhd_df['ADHD_Outcome'] == 0].shape[0]\n",
        "print(\"no adhd : \", no_adhd_num)\n",
        "print(\"adhd : \" , output_adhd_df.shape[0] - no_adhd_num)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "nNgj5ddPaQqR",
        "outputId": "1668b1d7-b593-4a19-c866-75f667b57583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (304x19900 and 19901x32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-835d95af0c67>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3197ddb27cce>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (304x19900 and 19901x32)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting Sex_F"
      ],
      "metadata": {
        "id": "B3ZsoLRUfcz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###### GET TEST SET IN PROPER FORM LIKE WE DID WITH TRAINING #######\n",
        "# Prepare test data (ensure it follows the same preprocessing as training data)\n",
        "test_features = test_fcm[connectivity_columns].values\n",
        "num_test_nodes = test_features.shape[0]\n",
        "\n",
        "# Create an adjacency matrix for test data (modify as needed)\n",
        "test_adjacency_matrix = np.ones(((int)(num_test_nodes/2.5), (int)(num_test_nodes/2.5)))\n",
        "np.fill_diagonal(test_adjacency_matrix, 0)  # No self-loops\n",
        "\n",
        "# Convert test data to PyTorch Geometric format\n",
        "test_data = Data(\n",
        "    x=torch.tensor(test_features, dtype=torch.float32).to(device),\n",
        "    edge_index=torch.tensor(np.array(np.where(test_adjacency_matrix)), dtype=torch.long).to(device),\n",
        ")\n",
        "\n",
        "######## EVAL #########\n",
        "# put model in eval mode\n",
        "sex_f_model.eval();\n",
        "\n",
        "# get predictions\n",
        "_, pred = sex_f_model(test_data.x, test_data.edge_index).max(dim=1)\n",
        "\n",
        "# output\n",
        "output_f_df = pd.DataFrame({\n",
        "    'participant_id' : test_fcm['participant_id'].values,\n",
        "    'Sex_F' : pred.cpu().numpy() #make pred and convert to numpy\n",
        "})\n",
        "\n",
        "print(output_f_df)\n",
        "no_f_num = output_f_df[output_f_df['Sex_F'] == 0].shape[0]\n",
        "print(\"not female: \", no_f_num)\n",
        "print(\"female : \" , output_f_df.shape[0] - no_f_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjPEXAGkc2Tm",
        "outputId": "6536ff76-71d1-4e2e-e4dd-12bee9e977a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    participant_id  Sex_F\n",
            "0     Cfwaf5FX7jWK      0\n",
            "1     vhGrzmvA3Hjq      0\n",
            "2     ULliyEXjy4OV      0\n",
            "3     LZfeAb1xMtql      0\n",
            "4     EnFOUv0YK1RG      0\n",
            "..             ...    ...\n",
            "299   UadZfjdEg7eG      0\n",
            "300   IUEHiLmQAqCi      0\n",
            "301   cRySmCadYFRO      1\n",
            "302   E3MvDUtJadc5      0\n",
            "303   dQJXfyRazknD      0\n",
            "\n",
            "[304 rows x 2 columns]\n",
            "not female:  277\n",
            "female :  27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "not sure what this was for?"
      ],
      "metadata": {
        "id": "S66XLBeU01tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#merging predictions\n",
        "test_results = test_results.merge(output_f_df, on=\"participant_id\")\n",
        "test_results.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XJJYPutC1RYq",
        "outputId": "cfd61f25-90f3-4f4c-988a-a0ce81219f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  participant_id  ADHD_Outcome  Sex_F_x  Sex_F_y\n",
              "0   Cfwaf5FX7jWK             1        0        0\n",
              "1   vhGrzmvA3Hjq             1        0        0\n",
              "2   ULliyEXjy4OV             1        0        0\n",
              "3   LZfeAb1xMtql             1        0        0\n",
              "4   EnFOUv0YK1RG             1        0        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-145fa04d-b63e-4eda-b047-2814c7ed956b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>ADHD_Outcome</th>\n",
              "      <th>Sex_F_x</th>\n",
              "      <th>Sex_F_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cfwaf5FX7jWK</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhGrzmvA3Hjq</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ULliyEXjy4OV</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LZfeAb1xMtql</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EnFOUv0YK1RG</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-145fa04d-b63e-4eda-b047-2814c7ed956b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-145fa04d-b63e-4eda-b047-2814c7ed956b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-145fa04d-b63e-4eda-b047-2814c7ed956b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d7de2266-ecdc-4efe-b9fb-5db8f933c4a8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7de2266-ecdc-4efe-b9fb-5db8f933c4a8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d7de2266-ecdc-4efe-b9fb-5db8f933c4a8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_results",
              "summary": "{\n  \"name\": \"test_results\",\n  \"rows\": 304,\n  \"fields\": [\n    {\n      \"column\": \"participant_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          \"G4HH3C3252g1\",\n          \"DkwrzlcjCXzl\",\n          \"m4i3mVopmQND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADHD_Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_F_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_F_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "final_pred.to_csv('pred.csv', index=False)\n",
        "files.download('pred.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Sw2vRqNczsdr",
        "outputId": "3832b101-c88a-4b71-a136-74c6b387c7fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_40bc195e-0e41-4481-8800-8349e6e94d3c\", \"pred.csv\", 5202)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#just making sure its in the correct format\n",
        "pred = pd.read_csv('pred.csv')\n",
        "pred.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Dos3NVnl0nbO",
        "outputId": "0880b12e-7be0-4d75-ae35-8e2662f18e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  participant_id  ADHD_Outcome  Sex_F\n",
              "0   Cfwaf5FX7jWK             1      1\n",
              "1   vhGrzmvA3Hjq             1      1\n",
              "2   ULliyEXjy4OV             1      1\n",
              "3   LZfeAb1xMtql             1      1\n",
              "4   EnFOUv0YK1RG             1      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01549b1f-a461-47e2-89e4-d74c0b1ebc58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>participant_id</th>\n",
              "      <th>ADHD_Outcome</th>\n",
              "      <th>Sex_F</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cfwaf5FX7jWK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vhGrzmvA3Hjq</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ULliyEXjy4OV</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LZfeAb1xMtql</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EnFOUv0YK1RG</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01549b1f-a461-47e2-89e4-d74c0b1ebc58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01549b1f-a461-47e2-89e4-d74c0b1ebc58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01549b1f-a461-47e2-89e4-d74c0b1ebc58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b1eb037-e161-4ce4-a490-e9e8889f1867\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b1eb037-e161-4ce4-a490-e9e8889f1867')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b1eb037-e161-4ce4-a490-e9e8889f1867 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pred",
              "summary": "{\n  \"name\": \"pred\",\n  \"rows\": 304,\n  \"fields\": [\n    {\n      \"column\": \"participant_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 304,\n        \"samples\": [\n          \"G4HH3C3252g1\",\n          \"DkwrzlcjCXzl\",\n          \"m4i3mVopmQND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADHD_Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex_F\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Dg-1wuF0zy4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}